{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5702e955-54f3-4f28-b6ee-40043dc23fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd4a272-4078-46a1-8fb8-0a2f1cf0b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_swimmer import SwimmerEnv\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "from models import *\n",
    "from core import generate_default_model_name\n",
    "Env = SwimmerEnv\n",
    "env = Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65725489-346f-49df-a672-c41e6d3da0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 64\n",
    "N_EPOCH = 12000\n",
    "n_candidates = 100\n",
    "bthreshold=1e-2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bnn = DMLP(state_dim=Env.state_dim, action_dim=Env.action_dim, mode='straight')\n",
    "bnn.to(device)\n",
    "bnn.train()\n",
    "\n",
    "lnn = DMLP(state_dim=Env.state_dim+Env.goal_dim, action_dim=Env.action_dim, mode='sum')\n",
    "lnn.to(device)\n",
    "lnn.train()\n",
    "\n",
    "boptimizer = torch.optim.Adam(bnn.parameters(), lr=1e-4, weight_decay=1e-8)\n",
    "bscheduler = torch.optim.lr_scheduler.ExponentialLR(boptimizer, gamma=0.996)\n",
    "\n",
    "loptimizer = torch.optim.Adam(lnn.parameters(), lr=1e-4, weight_decay=1e-8)\n",
    "lscheduler = torch.optim.lr_scheduler.ExponentialLR(loptimizer, gamma=0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbb7458-6d8c-4b0e-a6d4-47d8f530fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_action(nn, o, tensor_a, max_iter=30, mode='max', threshold=-1e-2):\n",
    "    '''\n",
    "        Laypunov: min\n",
    "        Barrier: max\n",
    "    '''\n",
    "    # size of a: (num_agents, n_candidates, action_dim)\n",
    "    \n",
    "    if len(o.shape)==2:\n",
    "        o = o.unsqueeze(1)\n",
    "    assert len(tensor_a.shape)==3\n",
    "    n_candidate = tensor_a.shape[1]\n",
    "    \n",
    "    nn.eval()\n",
    "    \n",
    "    vec = nn.get_vec(o).detach()\n",
    "    vec = vec.repeat((1, n_candidate, 1))    \n",
    "    \n",
    "    tensor_a.requires_grad = True\n",
    "    aoptimizer = torch.optim.Adam([tensor_a], lr=1)\n",
    "\n",
    "    iter_ = 0\n",
    "    while iter_ < max_iter:\n",
    "        value = nn.get_field(vec, tensor_a)\n",
    "        if mode=='max':\n",
    "            cvalue = (-value+threshold).relu()\n",
    "        else:\n",
    "            cvalue = (value-threshold).relu()\n",
    "        if torch.min(cvalue, dim=-1)[0].sum()==0:\n",
    "            break\n",
    "        aoptimizer.zero_grad()\n",
    "        cvalue.sum().backward()\n",
    "        torch.nn.utils.clip_grad_value_([tensor_a], 1e-2)\n",
    "        aoptimizer.step()\n",
    "        with torch.no_grad():\n",
    "            tensor_a[:] = tensor_a.clamp(-1, 1)\n",
    "        iter_ += 1\n",
    "        \n",
    "    value = nn.get_field(vec, tensor_a)\n",
    "    if mode=='max':\n",
    "        cvalue = (-value+threshold).relu()\n",
    "    else:\n",
    "        cvalue = (value-threshold).relu()    \n",
    "    \n",
    "    finalv = torch.zeros_like(value[:, 0])\n",
    "    finala = torch.zeros_like(tensor_a[:, 0, :])\n",
    "    valid = torch.min(cvalue, dim=-1)[0]==0\n",
    "    if mode=='max':\n",
    "        if (~valid).sum()!=0:\n",
    "            finalv[~valid] = torch.max(value[~valid], dim=-1)[0]\n",
    "            finala[~valid] = tensor_a[~valid, torch.max(value[~valid], dim=-1)[1]]\n",
    "        if (valid).sum()!=0:\n",
    "            tvalue = value.clone()\n",
    "            tvalue[cvalue!=0] = float('inf')\n",
    "            finalv[valid] = torch.min(tvalue[valid], dim=-1)[0]\n",
    "            finala[valid] = tensor_a[valid, torch.min(tvalue[valid], dim=-1)[1]]\n",
    "    else:\n",
    "        if (~valid).sum()!=0:\n",
    "            finalv[~valid] = torch.min(value[~valid], dim=-1)[0]\n",
    "            finala[~valid] = tensor_a[~valid, torch.min(value[~valid], dim=-1)[1]]\n",
    "        if (valid).sum()!=0:\n",
    "            tvalue = value.clone()\n",
    "            tvalue[cvalue!=0] = float('-inf')\n",
    "            finalv[valid] = torch.max(tvalue[valid], dim=-1)[0] \n",
    "            finala[valid] = tensor_a[valid, torch.max(tvalue[valid], dim=-1)[1]]\n",
    "    \n",
    "    nn.train()\n",
    "    \n",
    "    return tensor_a, value, finalv, finala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a8711c-df55-4818-944f-a9489487fea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_barrier(bnn, optimizer, buf, pbar, lamda=0.1, n_iter=10):\n",
    "    bnn.train()\n",
    "    buf.concat_goal = False\n",
    "    \n",
    "    # Set up function for computing value loss\n",
    "    def compute_loss(bnn, data, next_data):\n",
    "        value = bnn(**data)\n",
    "        next_value = bnn(**next_data)\n",
    "        \n",
    "        bloss1 = ((1e-2-value).relu())*data['prev_free']*data['next_free'] / (1e-9 + (data['next_free']).sum())\n",
    "        bloss2 = ((1e-2+value).relu())*(data['prev_danger']+data['next_danger']) / (1e-9 + (data['prev_danger']+data['next_danger']).sum())\n",
    "        bloss = bloss1.sum() + bloss2.sum()\n",
    "        \n",
    "        can_generate = 0  # (-dvalue-1e-2).relu()-(-dvalue-1e-2).relu().detach()\n",
    "        deriv = next_value-value+0.1*value\n",
    "        dloss = ((-deriv+1e-2+can_generate).relu())*data['prev_free']*data['next_free']*next_data['next_free']\n",
    "        dloss = dloss.sum() / (1e-9 + (data['prev_free']*data['next_free']*next_data['next_free']).sum())\n",
    "\n",
    "        return bloss, dloss\n",
    "    \n",
    "    # imitation learning\n",
    "    for i in range(n_iter):\n",
    "        loader, next_loader = buf.get()\n",
    "        for j, data_pair in enumerate(zip(loader, next_loader)):\n",
    "            data, next_data = data_pair \n",
    "            optimizer.zero_grad()\n",
    "            bloss, dloss = compute_loss(bnn, data, next_data)\n",
    "            loss = bloss + dloss\n",
    "            loss.backward()            \n",
    "            optimizer.step() \n",
    "            with torch.no_grad():\n",
    "                bvalue = bnn(**data)\n",
    "                b_mean = bvalue.mean()\n",
    "            desc = \"bloss %.6f, dloss %.6f, bmean %.6f\" % (bloss, dloss, b_mean)\n",
    "            pbar.set_description(desc)\n",
    "            optimizer.zero_grad()    \n",
    "    \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19458755-6afa-43d0-a023-d2cce014034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lyapunov(lnn, optimizer, buf, pbar, lamda=0.1, n_iter=10, n_candidates=100):\n",
    "    lnn.train()\n",
    "    buf.concat_goal = True\n",
    "    \n",
    "    # Set up function for computing value loss\n",
    "    def compute_loss(lnn, data):\n",
    "        value = lnn(**data).detach()\n",
    "        next_o = data['next_x']\n",
    "        \n",
    "        a = torch.rand(len(next_o), n_candidates, data['action'].shape[-1]).to(device).uniform_(-1, 1)\n",
    "        _, _, _, finala = sample_action(lnn, next_o, a, max_iter=0, mode='min', threshold=(value-1e-2).unsqueeze(1))\n",
    "        \n",
    "        value = lnn(**data)\n",
    "        next_value = lnn(**next_data)\n",
    "        next_value_neg = lnn(x=next_o, action=finala)        \n",
    "        goal_loss = ((value**2)*data['next_goal']).sum() / (1e-9 + data['next_goal'].sum()) + \\\n",
    "                    ((next_value**2)*next_data['next_goal']).sum() / (1e-9 + next_data['next_goal'].sum())\n",
    "        \n",
    "        deriv = next_value-value\n",
    "        dloss = ((deriv+1e-2).relu())\n",
    "        dloss = dloss.mean()\n",
    "        \n",
    "        deriv = next_value_neg-value\n",
    "        contrastloss = ((-deriv-1e-2).relu())\n",
    "        contrastloss = contrastloss.mean()        \n",
    "        \n",
    "        return goal_loss, dloss, contrastloss\n",
    "    \n",
    "    # imitation learning\n",
    "    for i in range(n_iter):\n",
    "        loader, next_loader = buf.get()\n",
    "        for j, data, next_data in enumerate(zip(loader, next_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            goal_loss, dloss, contrastloss = compute_loss(lnn, data, next_data)\n",
    "            loss = goal_loss + dloss + contrastloss\n",
    "            loss.backward()            \n",
    "            optimizer.step() \n",
    "            desc = \"goal_loss %.6f, dloss %.6f, closs %.6f\" % (goal_loss, dloss, closs)\n",
    "            pbar.set_description(desc)\n",
    "            optimizer.zero_grad()    \n",
    "    \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a9df3d3-8a33-4983-bcfb-9ce6b536a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create replay buffer\n",
    "import scipy\n",
    "from random import shuffle\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class DotDict(dict):\n",
    "    \"\"\"\n",
    "    a dictionary that supports dot notation \n",
    "    as well as dictionary access notation \n",
    "    usage: d = DotDict() or d = DotDict({'val1':'first'})\n",
    "    set attributes: d.val2 = 'second' or d['val2'] = 'second'\n",
    "    get attributes: d.val2 or d['val2']\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "    def __init__(self, dct):\n",
    "        for key, value in dct.items():\n",
    "            if hasattr(value, 'keys'):\n",
    "                value = DotDict(value)\n",
    "            self[key] = value\n",
    "            \n",
    "    def to(self, device):\n",
    "        for key, value in self.items():\n",
    "            self[key] = value.to(device)\n",
    "\n",
    "\n",
    "class GlobalReplayBuffer:\n",
    "    \"\"\"\n",
    "    A buffer for storing trajectories experienced by a PPO agent interacting\n",
    "    with the environment, and using Generalized Advantage Estimation (GAE-Lambda)\n",
    "    for calculating the advantages of state-action pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, batch=64):\n",
    "        self.obs_buf = []  \n",
    "        self.batch = batch\n",
    "        self.ptr = 0\n",
    "        self.max_size = size        \n",
    "        \n",
    "    def store(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Append one timestep of agent-environment interaction to the buffer.\n",
    "        \"\"\"\n",
    "#         assert self.ptr < self.max_size     # buffer has to have room so you can store\n",
    "        \n",
    "        obs = DotDict({})\n",
    "        for key, value in kwargs.items():\n",
    "            obs[key] = torch.as_tensor(value, dtype=torch.float)\n",
    "        self.obs_buf.append(obs)\n",
    "        self.ptr += 1\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"\n",
    "        Call this at the end of an epoch to get all of the data from\n",
    "        the buffer, with advantages appropriately normalized (shifted to have\n",
    "        mean zero and std one). Also, resets some pointers in the buffer.\n",
    "        \"\"\"\n",
    "        # collate_fn = lambda x: {x_.to(device) if print(x, x_) else 0 for x_ in default_collate(x)}\n",
    "        \n",
    "        def collate_fn(data):\n",
    "            \"\"\"\n",
    "               data: is a list of tuples with (example, label, length)\n",
    "                     where 'example' is a tensor of arbitrary shape\n",
    "                     and label/length are scalars\n",
    "            \"\"\"\n",
    "            data = default_collate(data)\n",
    "            for k, v in data.items():\n",
    "                data[k] = v.to(device)\n",
    "            if self.concat_goal:\n",
    "                data['x'] = torch.cat((data['x'], data['goal']), dim=-1)\n",
    "                data['next_x'] = torch.cat((data['next_x'], data['goal']), dim=-1)\n",
    "            return data\n",
    "        \n",
    "        loader = DataLoader(self.obs_buf, shuffle=True, batch_size=self.batch, collate_fn=collate_fn)\n",
    "        \n",
    "        return loader\n",
    "    \n",
    "    def relabel_l(self):\n",
    "        if lbuf.obs_buf[-1]['next_goal']==1:\n",
    "            return\n",
    "        \n",
    "        # choose a future state\n",
    "        chosen_idx = np.random.randint(1, len(self.obs_buf))\n",
    "        obs = self.obs_buf[chosen_idx]\n",
    "        new_goal = obs['x'].data.cpu().numpy()[:len(obs['goal'])]\n",
    "        for idx, obs, next_obs in zip(range(len(self.obs_buf)-1), self.obs_buf[:-1], self.obs_buf[1:]):\n",
    "            obs['goal'] = torch.as_tensor(new_goal, dtype=torch.float)\n",
    "            obs['next_goal'] = ((next_obs['x'][:len(new_goal)]-obs['goal']).norm() < 0.1)\n",
    "            if obs['next_goal']:\n",
    "                chosen_idx = idx + 1\n",
    "                \n",
    "        self.obs_buf = self.obs_buf[:chosen_idx]\n",
    "    \n",
    "    def relabel_b(self):\n",
    "        # TODO\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class GatherReplayBuffer:\n",
    "    \n",
    "    def __init__(self, batch=64, concat_goal=False):\n",
    "        self.buffers = []\n",
    "        self.batch = batch\n",
    "        self.concat_goal = concat_goal\n",
    "        \n",
    "    def append(self, buffer):\n",
    "        self.buffers.append(buffer)\n",
    "        \n",
    "    def get(self):\n",
    "        prev_o = []\n",
    "        prev_o.extend([o for b in self.buffers for o in b.obs_buf[:-1]])\n",
    "        next_o = []\n",
    "        next_o.extend([o for b in self.buffers for o in b.obs_buf[1:]])\n",
    "        \n",
    "        # collate_fn = lambda x: {x_.to(device) if print(x, x_) else 0 for x_ in default_collate(x)}\n",
    "        \n",
    "        def collate_fn(data):\n",
    "            \"\"\"\n",
    "               data: is a list of tuples with (example, label, length)\n",
    "                     where 'example' is a tensor of arbitrary shape\n",
    "                     and label/length are scalars\n",
    "            \"\"\"\n",
    "            data = default_collate(data)\n",
    "            for k, v in data.items():\n",
    "                data[k] = v.to(device)\n",
    "            if self.concat_goal:\n",
    "                data['x'] = torch.cat((data['x'], data['goal']), dim=-1)\n",
    "                data['next_x'] = torch.cat((data['next_x'], data['goal']), dim=-1)\n",
    "            return data\n",
    "            \n",
    "        l = list(zip(prev_o, next_o))\n",
    "        shuffle(l)\n",
    "        \n",
    "        loader = DataLoader([_[0] for _ in l], shuffle=False, batch_size=self.batch, collate_fn=collate_fn)\n",
    "        next_loader = DataLoader([_[1] for _ in l], shuffle=False, batch_size=self.batch, collate_fn=collate_fn)\n",
    "        \n",
    "        return loader, next_loader        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4fe37148-f20b-4993-9132-8d533667b900",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-86-b8530f2dbbda>\u001b[0m(44)\u001b[0;36msample_action\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     42 \u001b[0;31m        \u001b[0mcvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 44 \u001b[0;31m    \u001b[0mfinalv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m    \u001b[0mfinala\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     46 \u001b[0;31m    \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: unmatched ')'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit()\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9bddf9-cf00-48d6-97e9-6ce5ed5c15dc",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f360ec-774b-4a45-a5fa-38258ef95b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_action(bnn, lnn, o_b, o_l, a, bthreshold=-1e-2, lthreshold=-1e-2, max_iter=30):\n",
    "    # size of a: (num_agents, n_candidates, action_dim)\n",
    "    \n",
    "    a = a.reshape((-1, a.shape[-1]))\n",
    "    n_candidate = a.shape[0]\n",
    "    \n",
    "    bnn.eval()\n",
    "    lnn.eval()\n",
    "    \n",
    "    input_b = {k: v.to(device) for k, v in o_b.items()}\n",
    "    vecb = bnn.get_vec(**(input_b)).detach()\n",
    "    vecb = vecb.reshape(1, -1).repeat((n_candidate, 1))\n",
    "    \n",
    "    input_l = {k: v.to(device) for k, v in o_l.items()}\n",
    "    vecl = lnn.get_vec(x=torch.cat((input_l['x'], input_l['goal']), dim=-1)).detach()\n",
    "    vecl = vecl.reshape(1, -1).repeat((n_candidate, 1))    \n",
    "    \n",
    "    tensor_a = torch.FloatTensor(a).to(device)\n",
    "    tensor_a.requires_grad = True\n",
    "    aoptimizer = torch.optim.Adam([tensor_a], lr=1)\n",
    "\n",
    "    iter_ = 0\n",
    "    while iter_ < max_iter:\n",
    "        bvalue = bnn.get_field(vecb, tensor_a)\n",
    "        lvalue = lnn.get_field(vecl, tensor_a)\n",
    "        cvalue = (-bvalue+bthreshold).relu()+(lvalue-lthreshold).relu()\n",
    "        if torch.min(cvalue)==0:\n",
    "            break\n",
    "        aoptimizer.zero_grad()\n",
    "        cvalue.sum().backward()\n",
    "        torch.nn.utils.clip_grad_value_([tensor_a], 1e-2)\n",
    "        aoptimizer.step()\n",
    "        with torch.no_grad():\n",
    "            tensor_a[:] = tensor_a.clamp(-1, 1)\n",
    "        iter_ += 1\n",
    "\n",
    "    bvalue = bnn.get_field(vecb, tensor_a)\n",
    "    lvalue = lnn.get_field(vecl, tensor_a)\n",
    "    cvalue = (-bvalue+bthreshold).relu()+(lvalue-lthreshold).relu()\n",
    "    return tensor_a.data.cpu().numpy(), bvalue.data.cpu().numpy(), lvalue.data.cpu().numpy(), cvalue.data.cpu().numpy()\n",
    "\n",
    "def choose_action(cvalue):\n",
    "    if np.any(cvalue == 0):\n",
    "        idx = np.arange(len(cvalue))[cvalue == 0]\n",
    "        idx = np.random.choice(idx, 1)[0]\n",
    "    else:\n",
    "        idx = np.argmin(cvalue)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "aead5801-e121-484d-a650-3db8a6940f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "goal_loss 0.000000, dloss 0.000001:   0%|          | 13/12000 [00:17<4:28:06,  1.34s/it]            \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-4497432a164a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdescb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_barrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mdescl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lyapunov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#     if (epoch_i % 10 == 0) and (epoch_i != 0) and (epoch_i < 6000):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-155-6a06b7091c59>\u001b[0m in \u001b[0;36mtrain_lyapunov\u001b[0;34m(lnn, optimizer, buf, pbar, lamda, n_iter, n_candidates)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mgoal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-155-6a06b7091c59>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(lnn, data)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnext_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'next_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinala\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnext_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinala\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-153-b8530f2dbbda>\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(nn, o, tensor_a, max_iter, mode, threshold)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mn_candidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \"\"\"\n\u001b[0;32m-> 1465\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \"\"\"\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "# def is_counter_d(o, next_o, free, next_free, barrier, v_cur, v_next):\n",
    "#     counter_mse = np.abs(v_next - v_cur - barrier) > 1e-2\n",
    "#     return counter_mse\n",
    "\n",
    "# def is_counter_b(o, next_o, free, danger, barrier, v_cur, v_next):\n",
    "#     not_free = next_free.astype(float)<free.astype(float)\n",
    "#     counter_free = np.logical_and(free, v_cur > -1e-1)\n",
    "#     counter_obs = np.logical_and(danger, v_cur < 1e-1)\n",
    "#     counter_barrier = np.logical_and(v_next - v_cur > -0.1 * v_cur, free)\n",
    "#     return np.logical_or(np.logical_or(counter_free, counter_obs), counter_barrier)\n",
    "    \n",
    "\n",
    "max_episode_length     = Env.max_episode_steps\n",
    "EXPERIENCE_BUFFER_SIZE = Env.max_episode_steps\n",
    "\n",
    "name_dict = generate_default_model_name(Env)\n",
    "BMODEL_PATH = name_dict['db'].replace('dbgnn', 'dbnn')\n",
    "LMODEL_PATH = name_dict['dl'].replace('dlgnn', 'dlnn')\n",
    "LOG_FILE_L = 'cam_'+Env.__name__+'_l.txt'\n",
    "LOG_FILE_B = 'cam_'+Env.__name__+'_b.txt'\n",
    "open(LOG_FILE_L, 'w+').close()\n",
    "open(LOG_FILE_B, 'w+').close()\n",
    "bbuf = GlobalReplayBuffer(EXPERIENCE_BUFFER_SIZE)\n",
    "lbuf = GlobalReplayBuffer(EXPERIENCE_BUFFER_SIZE)\n",
    "env = Env()\n",
    "env.reset(); lthreshold=-1e3\n",
    "o = env._get_obs()\n",
    "\n",
    "pbar = tqdm(range(N_EPOCH))\n",
    "for epoch_i in pbar:\n",
    "    \n",
    "    total_trans = 0\n",
    "    unsafe_rate = 0\n",
    "#     buf.max_size += EXPERIENCE_BUFFER_SIZE\n",
    "    # Main loop: collect experience in env and update/log each epoch\n",
    "    while(total_trans<EXPERIENCE_BUFFER_SIZE):\n",
    "\n",
    "        o = env._get_obs()\n",
    "        \n",
    "        a_all = np.random.uniform(-1., 1., size=(n_candidates, env.action_dim))\n",
    "        o_l = o_b = {'x': torch.FloatTensor(o), 'goal': torch.FloatTensor(env.goal)}\n",
    "        a_refine, bvalue, lvalue, cvalue = iter_action(bnn, lnn, o_b, o_l, a_all, max_iter=min(epoch_i//100, 30), lthreshold=lthreshold, bthreshold=bthreshold)\n",
    "        idx = choose_action(cvalue)\n",
    "        a, bvalue, lvalue, cvalue = a_refine[idx, :], bvalue[idx], lvalue[idx], cvalue[idx]\n",
    "        lthreshold = lvalue - 1e-2\n",
    "        # a = np.random.uniform(-1, 1, size=(Env.action_dim,))\n",
    "        \n",
    "        next_o, r, d, info = env.step(a)\n",
    "        nowbuf.store(**info)\n",
    "\n",
    "        if d:\n",
    "            nowbuf.relabel_l()\n",
    "            allbuf.append(nowbuf)\n",
    "            env.reset(); lthreshold=-1e3; nowbuf = GlobalReplayBuffer(1024); \n",
    "\n",
    "    unsafe_rate = unsafe_rate / total_trans\n",
    "    \n",
    "    descb = train_barrier(bnn, boptimizer, bbuf, pbar=pbar, n_iter=10)\n",
    "    descl = train_lyapunov(lnn, loptimizer, lbuf, pbar=pbar, n_iter=10) \n",
    "    \n",
    "#     if (epoch_i % 10 == 0) and (epoch_i != 0) and (epoch_i < 6000):\n",
    "#         bscheduler.step()\n",
    "#         lscheduler.step()\n",
    "    \n",
    "    with open(LOG_FILE_L, 'a+') as f:\n",
    "        f.write(descl+'\\t'+str(pbar.last_print_n)+'\\n')\n",
    "    with open(LOG_FILE_B, 'a+') as f:\n",
    "        f.write(descb+'\\t'+str(pbar.last_print_n)+'\\t'+'unsafe rate: '+str(unsafe_rate)+'\\n')     \n",
    "    \n",
    "    torch.save(bnn.state_dict(), BMODEL_PATH)\n",
    "    torch.save(lnn.state_dict(), LMODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "508e3255-43c9-432c-8719-78d3633076bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a95b7d68-a360-443b-91d9-12c3aead847a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/rainorangelemon/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m(1753)\u001b[0;36mlinear\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1751 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1752 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1753 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1754 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1755 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit()\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a04ef1-114f-4202-b50e-6518b68ecf98",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1efba87e-06ea-4e07-9098-feb81bad8e96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.          0.18508455] 0.06435737 0.07643822 1000.06433\n",
      "[-1. -1.] 0.08304545 0.09719533 0.028688084\n",
      "[1. 1.] 0.022714553 0.10902397 0.0\n",
      "[1. 1.] 0.021035004 0.043871645 0.008320451\n",
      "[-1. -1.] 0.07122941 0.06251663 0.06019441\n",
      "[-0.5870377 -1.       ] 0.081835255 0.023417275 0.020605844\n",
      "[1. 1.] 0.0066363253 0.13620774 0.0\n",
      "[0.2722642 1.       ] 0.011613596 0.0020998418 0.022877429\n",
      "[-1. -1.] 0.070142314 0.025615757 0.06852872\n",
      "[ 0.28634393 -0.27431247] 0.038593262 -0.021201644 0.031201644\n",
      "[0.51681185 1.        ] 0.0052824663 0.010600628 0.0\n",
      "[-1. -1.] 0.051720716 0.036437448 0.05643825\n",
      "[ 0.32304662 -0.7526628 ] 0.03467583 -0.010475455 0.020475455\n",
      "[0.64764667 1.        ] 0.004692968 -0.014261765 0.024261765\n",
      "[-1. -1.] 0.046387747 0.04511833 0.05169478\n",
      "[ 0.5528521 -0.4121422] 0.020557651 0.008372053 0.0016279472\n",
      "[-0.06452352  1.        ] 0.0117154475 0.061053164 0.001157796\n",
      "[-0.3520448 -1.       ] 0.02656737 0.07142775 0.024851922\n",
      "[1.         0.25921556] 0.010344019 0.05065412 0.0\n",
      "[-0.84635264  0.24766012] 0.03106184 0.060083818 0.03071782\n",
      "[-0.5729513 -1.       ] 0.025408532 0.089208126 0.004346693\n",
      "[1.         0.62640333] 0.014503596 0.030909661 0.0\n",
      "[0.62298495 1.        ] 0.012321248 -0.018419856 0.036237508\n",
      "[-1. -1.] 0.037894398 0.055036623 0.03557315\n",
      "[ 0.74370337 -0.51380044] 0.027326422 0.035176396 0.0\n",
      "[ 0.61586183 -0.54498833] 0.0075741336 0.08553776 0.0\n",
      "[ 1.        -0.2724699] 0.0025302637 0.09137863 0.00495613\n",
      "[1.         0.75622797] 0.0047721434 0.09465736 0.0122418795\n",
      "[-1. -1.] 0.03457599 0.091575816 0.039803848\n",
      "[ 0.9268097 -1.       ] 0.043958172 0.029544195 0.01938218\n",
      "[ 0.87209374 -0.09803531] 0.001919134 0.089557916 0.0\n",
      "[1.        0.9160137] 0.006589028 0.09309639 0.014669894\n",
      "[-1. -1.] 0.034316048 0.08782005 0.03772702\n",
      "[ 0.17813087 -1.        ] 0.0374837 0.021405123 0.013167651\n",
      "[ 0.6478309  -0.48471203] 0.0054029375 0.090398565 0.0\n",
      "[ 1.         -0.45105797] 0.003093195 0.10329123 0.0076902574\n",
      "[ 1.        -0.3148712] 0.00229279 0.103986815 0.009199595\n",
      "[1.         0.18073997] 0.0014115458 0.105627134 0.009118755\n",
      "[-0.52178264 -0.51552296] 0.024422713 0.09011373 0.03301117\n",
      "[1.        0.9298986] 0.021777272 0.08946869 0.0073545594\n",
      "[-1.         -0.96842897] 0.040064447 0.06423791 0.028287174\n",
      "[1.         0.56509894] 0.042543538 0.048145507 0.012479091\n",
      "[-1.         -0.57122386] 0.036394246 0.078238055 0.0038507096\n",
      "[ 1.        -0.6203756] 0.009665756 0.08528666 0.0\n",
      "[1.        0.6907124] 0.0033794548 0.09329651 0.0037136993\n",
      "[-1. -1.] 0.03473649 0.089372724 0.041357037\n",
      "[ 0.86967164 -0.34117913] 0.0337679 0.038216904 0.009031409\n",
      "[1.         0.79717004] 0.004513004 0.093906984 0.0\n",
      "[-1. -1.] 0.034727283 0.08625743 0.040214278\n",
      "[ 0.90453756 -1.        ] 0.04322809 0.027880862 0.018500807\n",
      "[ 0.8095463  -0.31999317] 0.0040934402 0.091676295 0.0\n",
      "[1. 1.] 0.0075077303 0.09723899 0.01341429\n",
      "[-1. -1.] 0.033161078 0.08817987 0.03565335\n",
      "[-0.29767978 -1.        ] 0.03673602 0.028288316 0.013574941\n",
      "[1.         0.24946095] 0.0071820524 0.12042621 0.0\n",
      "[ 0.56687534 -0.8707943 ] 0.009651044 0.09966987 0.012468992\n",
      "[ 1.         -0.43079114] 0.0030516996 0.107641816 0.0034006552\n",
      "[1.         0.12681586] 0.0012344704 0.109896705 0.008182771\n",
      "[-0.18958306 -0.3919844 ] 0.018278535 0.09706646 0.027044065\n",
      "[1.         0.81998104] 0.00890492 0.0949921 0.0006263843\n",
      "[-1. -1.] 0.0328831 0.09234384 0.03397818\n",
      "[ 0.8691236  -0.53793555] 0.03242838 0.05079415 0.00954528\n",
      "[1.         0.46681497] 0.0020360872 0.10555793 0.0\n",
      "[-1. -1.] 0.036675617 0.09286007 0.044639528\n",
      "[1.        0.9493844] 0.03835029 0.051692266 0.011674674\n",
      "[-1. -1.] 0.043071605 0.07548237 0.0147213135\n",
      "[1.        0.6119108] 0.033917397 0.04804277 0.00084579363\n",
      "[-1.         -0.29111055] 0.035514466 0.079157144 0.011597069\n",
      "[-0.12318119 -1.        ] 0.009590004 0.093967155 0.0\n",
      "[1. 1.] 0.0043050456 0.13119785 0.004715042\n",
      "[-0.18775094  0.9662175 ] 0.016753651 0.05798123 0.022448605\n",
      "[-0.1376285 -1.       ] 0.020009935 0.13533254 0.0132562835\n"
     ]
    }
   ],
   "source": [
    "from gym_swimmer import SwimmerEnv\n",
    "from stable_baselines3 import PPO\n",
    "from tqdm import tqdm \n",
    "\n",
    "env = SwimmerEnv()\n",
    "model = PPO.load(\"swimmer/best_model.zip\")\n",
    "\n",
    "env = Env()\n",
    "imgs = [env.sim.render(600, 300)]\n",
    "\n",
    "num_tot = 0\n",
    "num_goaled = 0 \n",
    "num_collision = 0\n",
    "\n",
    "obs = env.reset(); lthreshold=-1e3\n",
    "ts = 0\n",
    "while True:\n",
    "    ts += 1 \n",
    "    \n",
    "    o = env._get_obs()\n",
    "    a_oracle = model.predict(o)[0]\n",
    "    a_all = np.random.uniform(-1., 1., size=(1000, env.action_dim))\n",
    "    a_all[0,:] = a_oracle\n",
    "    \n",
    "    o_l = o_b = {'x': torch.FloatTensor(o), 'goal': torch.FloatTensor(env.goal)}\n",
    "    a_refine, bvalue, lvalue, cvalue = iter_action(bnn, lnn, o_b, o_l, a_all, max_iter=0, lthreshold=lthreshold, bthreshold=bthreshold)\n",
    "    idx = choose_action(cvalue)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    ac, bvalue, lvalue, cvalue = a_refine[idx, :], bvalue[idx], lvalue[idx], cvalue[idx]\n",
    "    lthreshold = lvalue - 1e-2\n",
    "    \n",
    "    print(ac, lvalue, bvalue, cvalue)\n",
    "    obs, rw, done, _ = env.step(ac)\n",
    "    if env.sim.data.ncon!=0:\n",
    "        print('collision')\n",
    "    imgs.append(env.sim.render(600, 300))\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e7c07d77-f685-48c0-9b66-c2ca471fbfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "ims = [Image.fromarray(np.flip(a_frame, axis=0)) for a_frame in imgs]\n",
    "ims[0].save(\"cam.gif\", save_all=True, append_images=ims[1:], duration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19107d58-aeec-4cff-9d42-1c3d3daec3e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-20-b0ab67fbcaba>\u001b[0m(49)\u001b[0;36msample_action\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     47 \u001b[0;31m    \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     48 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 49 \u001b[0;31m        \u001b[0mfinalv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     50 \u001b[0;31m        \u001b[0mfinala\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     51 \u001b[0;31m        \u001b[0mtvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  valid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  cvalue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  cvalue.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.min(cvalue, dim=-1)[0]==0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.7262e-03,  5.0118e-03, -8.4718e-03,  9.9360e-03,  1.3209e-02,\n",
      "          8.2699e-03,  4.2516e-03,  1.6563e-02,  7.1831e-03,  1.3738e-03,\n",
      "         -5.8962e-03, -6.5514e-03,  1.4476e-02, -2.3273e-03, -1.6408e-03,\n",
      "          1.1450e-03,  1.0558e-03,  1.3862e-02, -5.8483e-03, -4.7138e-03,\n",
      "         -7.7967e-03, -6.1636e-04,  9.5766e-03,  5.8739e-03, -8.6961e-03,\n",
      "          2.2245e-03, -7.9326e-03, -4.1428e-03,  1.1588e-02,  6.9545e-03,\n",
      "         -4.8973e-03, -2.9604e-03,  7.7139e-03,  3.7160e-03,  8.0969e-03,\n",
      "          1.1821e-02, -7.1511e-03, -9.0692e-04, -6.1387e-03,  5.6423e-03,\n",
      "          5.0686e-03,  1.0692e-02,  9.8625e-03, -8.3699e-03,  7.5419e-03,\n",
      "         -5.5405e-03,  7.9922e-03,  5.4960e-03, -7.7494e-03,  6.0038e-03,\n",
      "          1.6131e-02,  2.2360e-03, -1.8093e-04,  4.2529e-03,  6.9596e-03,\n",
      "          8.6023e-03,  8.7183e-04,  1.3906e-02,  8.2790e-03,  1.5417e-02,\n",
      "          1.6796e-03,  1.3456e-02,  2.9710e-03, -2.0279e-03,  7.8851e-03,\n",
      "          1.2089e-02,  1.3287e-02, -3.7957e-03, -5.1724e-03,  7.2501e-03,\n",
      "         -8.9028e-03,  1.4359e-02, -4.2256e-03,  1.3714e-02,  8.4238e-03,\n",
      "         -9.4522e-04, -2.0615e-03,  1.1758e-02,  6.3467e-03,  1.2141e-02,\n",
      "          2.1012e-03,  5.8173e-05,  1.1523e-02,  1.1671e-02,  8.6522e-03,\n",
      "          8.9023e-03, -8.6577e-03,  9.4800e-03,  3.3632e-03,  1.2649e-02,\n",
      "         -9.1801e-04, -9.0406e-04,  1.4779e-02,  8.4730e-03, -2.5234e-03,\n",
      "          1.5905e-03, -1.1648e-03, -1.5995e-03,  1.4796e-02,  5.3991e-03,\n",
      "         -4.9085e-03, -5.3174e-03,  1.5337e-02, -3.9539e-03,  1.2452e-02,\n",
      "         -8.6125e-04, -1.8469e-03,  1.3166e-02, -5.9646e-03,  1.0713e-03,\n",
      "          8.4092e-04,  6.6932e-03,  5.8240e-03, -1.8168e-03,  1.6114e-03,\n",
      "          1.4513e-02,  9.8796e-03,  2.1217e-03,  1.3258e-02,  3.0984e-03,\n",
      "          8.4930e-03,  5.7533e-03, -5.5104e-03,  9.1154e-03,  7.2464e-03,\n",
      "         -5.2442e-03,  1.2243e-02, -3.4049e-03,  6.2367e-03, -1.4517e-03,\n",
      "         -4.0943e-03,  4.8560e-03,  1.2039e-02,  9.6781e-03,  7.6535e-03,\n",
      "          7.0508e-03,  9.4741e-03,  4.8943e-03,  2.9825e-03,  1.2669e-02,\n",
      "         -5.6118e-04, -4.2997e-03, -2.4731e-03,  2.0601e-03, -2.8271e-03,\n",
      "         -6.4891e-03,  9.4119e-03,  3.9258e-04, -3.9435e-03,  4.8840e-04,\n",
      "          1.6437e-03,  2.3915e-03,  1.8079e-03, -7.0973e-03,  5.0093e-03,\n",
      "         -1.3450e-03, -4.1631e-03,  7.0534e-03,  1.4740e-02, -5.9177e-03,\n",
      "          5.5028e-05,  1.2515e-02, -4.9876e-03, -6.3648e-03,  1.0414e-02,\n",
      "          2.6197e-03,  5.0118e-04, -7.9689e-03,  1.3960e-02,  1.1765e-02,\n",
      "         -1.7567e-03,  8.0983e-03, -3.9344e-03,  1.4260e-03,  1.1978e-02,\n",
      "         -1.9320e-03, -6.7396e-03, -3.9479e-03,  6.6785e-03,  4.8245e-03,\n",
      "         -6.4081e-03,  1.0091e-02,  1.2755e-02,  3.4396e-03,  4.9599e-03,\n",
      "         -4.8395e-03, -4.5603e-03, -4.1670e-03,  7.4305e-03,  6.0922e-03,\n",
      "          7.7568e-03, -7.5850e-03,  2.1833e-03,  1.0875e-02, -6.4460e-03,\n",
      "         -1.2379e-03,  8.7711e-03,  5.5250e-03,  1.4834e-02,  3.2901e-03,\n",
      "          7.7915e-03,  1.5078e-02,  1.3642e-02,  4.5115e-04, -8.4855e-03,\n",
      "         -5.1686e-03,  8.0419e-04, -2.2560e-03, -1.7476e-03, -7.2890e-04,\n",
      "          8.4948e-03, -5.7547e-03, -8.0900e-03, -6.5713e-03,  3.6161e-03,\n",
      "          1.1907e-02, -7.0312e-03, -6.4893e-03,  1.1388e-02,  1.3784e-02,\n",
      "         -7.4894e-04, -4.1308e-03,  4.4472e-03,  5.4738e-04, -9.0704e-03,\n",
      "          1.3928e-02, -7.2003e-03, -4.8668e-03,  3.9329e-03, -6.6179e-03,\n",
      "          1.0251e-02,  1.0998e-03,  1.2420e-02,  1.7304e-05, -2.3608e-03,\n",
      "         -2.3816e-04, -5.7412e-03, -8.8303e-03,  3.4500e-03,  8.3456e-03,\n",
      "         -5.5083e-03,  1.4456e-02,  5.7830e-04,  1.5322e-02,  5.3841e-04,\n",
      "         -4.7694e-04,  1.6411e-02,  7.6485e-03,  1.1067e-02,  6.8228e-03,\n",
      "         -6.8788e-03,  1.5555e-02,  6.6691e-04, -3.0440e-03,  8.7175e-04,\n",
      "         -1.2888e-03,  1.0977e-02,  8.5076e-03,  1.2759e-02, -5.2030e-03,\n",
      "          1.3637e-02,  3.6120e-04,  7.6623e-03,  1.4140e-02, -8.6442e-03,\n",
      "          1.1377e-04,  6.9931e-03, -9.2935e-03,  1.1370e-02,  1.1502e-02,\n",
      "         -3.5466e-03,  2.4353e-04,  4.8363e-03,  6.1495e-03, -6.3862e-03,\n",
      "         -9.0739e-03,  1.2319e-02,  1.4165e-02,  1.4187e-02,  6.0836e-04,\n",
      "          1.2283e-02,  1.2493e-02,  6.2673e-04, -6.7296e-03,  8.9161e-03,\n",
      "          1.7287e-03,  1.1624e-02, -3.0827e-03, -4.1075e-03, -4.0325e-03,\n",
      "         -4.8596e-03,  1.0356e-02,  2.4083e-03, -1.1918e-03,  1.3350e-02,\n",
      "         -2.3766e-03,  9.5953e-03,  3.5281e-03, -2.4856e-03,  1.0691e-02,\n",
      "          2.6266e-03,  1.1842e-02,  1.5435e-02,  8.9179e-03,  3.0683e-03,\n",
      "         -3.4758e-03,  1.5001e-03,  8.9264e-03, -2.7495e-04, -5.9878e-03,\n",
      "          9.4513e-03,  1.2004e-03,  1.3970e-02,  9.6897e-03, -1.5902e-03,\n",
      "          4.7301e-03, -2.7499e-03,  3.2783e-04, -5.6544e-03, -7.3866e-03,\n",
      "          3.1200e-03,  4.8744e-05,  1.0079e-02,  1.2304e-02, -3.5598e-03,\n",
      "          4.3927e-03, -4.7388e-03,  7.0061e-03,  5.4373e-03, -4.3531e-03,\n",
      "         -6.4941e-03,  1.2351e-02,  1.2059e-03,  1.0960e-02, -3.3482e-03,\n",
      "          1.2061e-02, -3.9130e-03, -7.4889e-03, -4.1721e-03,  1.0708e-02,\n",
      "         -6.0759e-03, -7.7221e-03,  5.9234e-03, -3.5409e-03, -6.7822e-03,\n",
      "          1.2976e-02,  5.7657e-03,  5.6276e-04, -3.5763e-03, -7.0026e-03,\n",
      "         -5.2676e-03,  4.1117e-03,  7.3218e-03,  2.3111e-03,  7.0462e-03,\n",
      "         -6.0088e-03,  5.9098e-03,  6.3113e-03,  2.7732e-04, -5.0505e-03,\n",
      "          5.1066e-03, -3.5651e-03,  8.8152e-03,  1.3852e-02,  8.2780e-03,\n",
      "          7.8038e-03, -2.7311e-03,  1.6691e-03, -2.3919e-03,  5.0457e-03,\n",
      "          1.3138e-02, -7.0659e-03, -4.6164e-03,  1.0447e-02, -3.1103e-04,\n",
      "         -2.5065e-03,  4.5273e-03, -6.7655e-03,  3.7407e-03,  7.9288e-03,\n",
      "          8.5059e-03,  2.6307e-04,  5.0944e-03,  1.1074e-02, -6.2293e-03,\n",
      "         -4.9420e-03, -2.9163e-03,  3.5507e-03,  3.2893e-04,  1.4280e-02,\n",
      "         -1.6280e-03, -5.4981e-03,  1.3464e-02,  3.4321e-03,  2.5264e-03,\n",
      "          1.2944e-02, -7.4794e-03,  1.3681e-02,  6.1409e-03,  5.3718e-03,\n",
      "          7.0883e-03, -5.6749e-03,  8.7427e-03, -1.3427e-03, -9.2071e-03,\n",
      "         -6.8311e-03,  8.5486e-04,  1.2353e-02, -6.4042e-03, -2.2961e-03,\n",
      "          7.8260e-03, -3.9774e-03,  8.6480e-03, -3.8160e-03,  4.2034e-04,\n",
      "          1.3571e-02, -2.0837e-03, -2.3096e-03,  1.9335e-03, -5.1990e-03,\n",
      "         -3.6694e-03,  5.6199e-03,  1.1538e-02,  1.3941e-02,  1.2063e-02,\n",
      "          3.6592e-05, -6.2214e-03, -8.7535e-03, -7.6811e-03,  6.3327e-04,\n",
      "          1.1294e-02, -1.8834e-03,  8.6509e-03,  1.3746e-02,  1.3109e-02,\n",
      "         -8.4648e-03,  8.7800e-03,  3.6742e-03,  2.9495e-03,  1.5082e-02,\n",
      "         -4.3053e-03, -2.4203e-04,  4.8418e-03,  9.1097e-03,  1.3091e-02,\n",
      "         -8.4836e-03,  8.4119e-03, -4.3908e-03,  9.8076e-03,  2.5416e-03,\n",
      "         -8.6858e-03, -6.6229e-03, -4.2008e-04, -4.7253e-03,  2.2681e-03,\n",
      "          8.7720e-03, -7.1200e-03,  5.9831e-03,  1.2202e-03,  1.3729e-02,\n",
      "          5.1349e-04,  1.2038e-02,  9.9681e-03,  1.5271e-02, -2.0755e-04,\n",
      "          1.0996e-02, -4.9400e-03, -5.4536e-03, -4.6266e-03, -5.0961e-03,\n",
      "          5.5956e-04,  7.8323e-03, -2.5346e-03,  5.7824e-03,  1.3615e-02,\n",
      "          3.6520e-03,  8.4042e-03, -2.5398e-03, -4.8103e-03,  2.6151e-03,\n",
      "          1.9754e-03, -2.5963e-03, -1.6471e-03, -5.9323e-03,  4.8741e-03,\n",
      "         -6.5839e-03, -9.4406e-04, -7.4046e-03, -4.0979e-03,  6.2384e-03,\n",
      "          1.0922e-02, -4.0996e-03,  4.5167e-03,  1.4551e-02,  9.8166e-03,\n",
      "          1.0290e-02, -2.3665e-03,  2.7061e-03,  1.5171e-03, -7.3030e-03,\n",
      "         -3.5124e-03, -4.2688e-04,  2.6767e-03,  3.0945e-03, -1.4876e-03,\n",
      "          7.3981e-03, -1.9703e-03,  3.8556e-03,  2.1143e-03,  6.9249e-03,\n",
      "          1.5167e-03, -7.5720e-03,  1.2746e-02, -3.4290e-03,  1.0835e-02,\n",
      "          8.9763e-03,  9.0723e-03,  1.5230e-02,  3.8856e-03,  2.7020e-03,\n",
      "          1.0313e-02,  1.2593e-02,  1.3612e-02,  1.1316e-02,  1.4830e-02,\n",
      "         -5.9404e-04, -1.8016e-03, -6.1711e-03,  8.4510e-03, -3.6706e-03,\n",
      "          1.9324e-03,  2.1808e-03, -2.1194e-03,  4.5151e-03,  8.4444e-03,\n",
      "         -1.8720e-03, -2.0541e-03, -3.8875e-03,  9.3532e-03,  1.3266e-02,\n",
      "          5.3228e-03, -8.2394e-03, -2.7467e-03, -6.3430e-03, -3.5769e-03,\n",
      "          7.1544e-03, -7.0993e-03,  7.4664e-03, -1.5082e-04, -1.7033e-03,\n",
      "          7.6228e-03,  1.5783e-02,  2.5621e-04,  1.6549e-03,  4.5213e-03,\n",
      "         -6.0061e-03,  1.4558e-02,  6.7571e-03,  3.4410e-03,  5.4914e-03,\n",
      "         -1.5908e-03,  2.8500e-03, -4.3107e-03,  1.0099e-02,  1.4851e-02,\n",
      "          1.2786e-02,  1.0471e-02, -8.3990e-03, -2.6636e-03,  1.0477e-02,\n",
      "          7.4289e-03,  1.4751e-02, -2.7899e-03, -7.6188e-03,  1.1663e-02,\n",
      "          8.6712e-03,  1.4623e-02,  1.0504e-02,  7.4649e-03, -5.1831e-03,\n",
      "          5.2942e-03,  5.4346e-03, -9.2022e-04,  9.5643e-03,  5.7811e-03,\n",
      "          1.3491e-04,  1.5128e-02,  6.7120e-03, -5.4544e-03,  2.0851e-03,\n",
      "          1.3551e-02,  2.4410e-03,  1.2211e-02,  1.2415e-02, -7.7569e-04,\n",
      "          2.8427e-03,  5.7627e-03, -2.7878e-03, -1.7796e-03, -3.3231e-03,\n",
      "         -5.6208e-04,  1.6148e-02,  6.0140e-03,  8.0456e-03,  4.1423e-03,\n",
      "          1.4708e-02,  9.9927e-04, -6.1298e-03,  1.8226e-03,  1.1774e-02,\n",
      "          7.2094e-03, -7.4453e-03, -1.2184e-03, -4.4549e-03, -3.4459e-03,\n",
      "          1.2049e-02,  6.4980e-03, -3.3706e-03, -4.7902e-03,  3.4875e-03,\n",
      "         -3.5762e-03,  1.7599e-03,  6.3805e-03,  5.2800e-03, -5.1880e-03,\n",
      "         -4.8836e-03,  7.6299e-04,  8.4989e-03,  1.0033e-02, -4.0478e-03,\n",
      "          6.7415e-03,  1.1780e-03,  3.7943e-04,  4.2155e-03,  3.3807e-03,\n",
      "         -3.8039e-03,  1.6029e-02,  8.5924e-04,  1.1362e-02,  1.5177e-02,\n",
      "          5.4358e-03,  4.9124e-03,  1.4056e-02,  1.0004e-02,  1.3501e-02,\n",
      "          1.4402e-03, -1.5489e-03, -3.1549e-03, -5.1841e-03,  5.1747e-03,\n",
      "          4.3587e-03,  7.7534e-03,  1.5364e-02, -6.4056e-03,  1.0520e-02,\n",
      "         -4.9351e-03,  9.5177e-04,  7.4984e-03, -7.5757e-03,  5.2663e-03,\n",
      "          9.7012e-03,  2.2677e-03,  2.6908e-03, -7.5081e-03,  5.9786e-04,\n",
      "          2.0559e-03, -9.7904e-04,  3.2052e-04,  8.9349e-03,  2.5687e-03,\n",
      "          2.2596e-03, -2.1645e-03,  1.1801e-02, -5.7197e-03,  1.4307e-02,\n",
      "         -5.4291e-05,  9.3502e-04,  3.0029e-03, -8.7357e-03,  3.8591e-03,\n",
      "         -6.0456e-03, -6.2190e-03,  1.5834e-02,  2.6187e-04,  1.3451e-02,\n",
      "          3.7498e-03, -5.2557e-03, -6.5880e-03,  1.4690e-02,  1.5283e-02,\n",
      "         -7.7917e-04,  2.9903e-03,  1.2832e-02,  1.4223e-03,  7.4757e-03,\n",
      "          8.1242e-03,  1.4951e-02,  6.5861e-03,  1.7756e-03, -5.6654e-03,\n",
      "          1.0053e-02,  1.3389e-02,  2.4023e-03, -1.5102e-03,  1.0572e-02,\n",
      "         -7.4935e-03,  1.3406e-02,  5.6959e-03,  1.0548e-02,  1.0172e-02,\n",
      "          9.8735e-03,  9.1596e-04,  1.0450e-02,  1.5923e-02,  5.5547e-03,\n",
      "          1.0647e-02, -2.7959e-03, -2.1850e-03,  1.1943e-02,  5.7902e-03,\n",
      "         -4.0486e-03,  1.1026e-03, -7.1562e-03,  1.0720e-03,  5.2278e-03,\n",
      "         -4.9168e-03,  6.4496e-04, -5.5420e-03, -7.2418e-03, -2.8547e-03,\n",
      "          4.0582e-03,  6.3719e-03, -3.0321e-03, -6.2470e-04,  5.1834e-03,\n",
      "          1.3569e-02,  1.4878e-02,  7.1577e-03,  6.7504e-03,  1.0437e-04,\n",
      "          7.3773e-03,  6.4806e-03,  8.3883e-03,  4.9969e-03, -5.8171e-04,\n",
      "         -3.2179e-03,  6.1298e-03,  1.1859e-02, -5.7030e-03, -4.4633e-04,\n",
      "          1.0268e-03,  3.9207e-03, -6.5505e-03, -3.1607e-03,  1.5882e-02,\n",
      "          6.1456e-03,  1.3889e-02,  2.8017e-03,  1.3533e-02,  1.5205e-02,\n",
      "         -5.4921e-03,  7.6357e-03,  1.2119e-02,  1.0594e-02, -4.1915e-03,\n",
      "         -2.0961e-03,  5.6408e-03, -9.2221e-03,  1.3997e-02, -4.4605e-03,\n",
      "          3.3352e-03, -5.7712e-03, -2.2534e-03, -1.1662e-03, -5.0617e-03,\n",
      "          1.5149e-02,  8.4195e-03,  7.8115e-03,  5.3106e-03,  1.3202e-02,\n",
      "          1.3057e-02,  9.3790e-03, -7.6760e-03,  1.0813e-02,  9.2993e-03,\n",
      "          1.5637e-02,  1.4809e-02, -3.5237e-03,  2.3450e-03, -2.0764e-03,\n",
      "          3.7799e-03, -3.4310e-03,  1.0761e-02,  9.5241e-04, -1.7118e-03,\n",
      "         -5.9377e-03,  5.3049e-03,  2.6266e-03,  1.4784e-02,  1.1929e-02,\n",
      "          4.9455e-03,  5.5216e-03, -6.9790e-03,  1.5463e-02,  7.7353e-03,\n",
      "          1.5136e-03, -8.5946e-03,  1.6108e-03,  9.7144e-04,  1.4215e-02,\n",
      "          4.8471e-03,  9.7473e-03,  4.3866e-03,  7.0651e-03,  2.8368e-03,\n",
      "          4.6924e-03, -7.7515e-03,  6.2541e-03, -3.9990e-03,  9.0507e-03,\n",
      "         -6.6092e-03,  5.6450e-03,  1.4196e-02, -5.2213e-03, -2.2006e-04,\n",
      "          1.6353e-03, -8.6619e-04, -3.6917e-03,  1.2221e-02, -4.5744e-03,\n",
      "         -3.5959e-03,  1.4928e-02,  4.6335e-03, -2.6316e-03,  4.5393e-03,\n",
      "          1.6520e-03,  4.7589e-03,  3.7517e-03, -3.2496e-03,  1.1368e-02,\n",
      "          9.8368e-03,  2.1585e-03,  3.6273e-03,  4.1122e-03, -7.2261e-03,\n",
      "          3.2218e-03, -6.1753e-03, -7.3064e-03, -8.5299e-04, -6.9316e-03,\n",
      "          1.2063e-02,  7.6056e-03,  6.5814e-03,  9.6408e-03, -1.6304e-03,\n",
      "          1.4590e-02,  1.2949e-02, -5.8081e-03, -1.5012e-03,  2.0517e-04,\n",
      "         -5.2925e-03, -6.4797e-03,  4.5884e-03,  6.8136e-03,  1.3114e-02,\n",
      "          1.1170e-02,  6.2510e-03,  1.2223e-02, -5.8108e-03, -4.2340e-03,\n",
      "          1.3975e-02, -1.7603e-03,  4.1460e-03,  3.1697e-03, -5.3674e-04,\n",
      "          9.1252e-03, -7.5733e-04,  6.3280e-03,  1.2723e-02, -4.7463e-03,\n",
      "          1.0698e-02,  1.5681e-02,  1.3191e-02, -1.5336e-03,  1.4592e-02,\n",
      "          1.1599e-02, -7.5141e-03,  8.8786e-03,  1.4698e-02,  3.5841e-03,\n",
      "          5.9574e-03, -5.2002e-03, -6.5644e-03,  7.8766e-03, -3.8784e-03,\n",
      "         -1.7471e-03, -6.2004e-03,  1.5942e-02,  2.0879e-03,  3.8314e-03,\n",
      "         -2.3403e-03,  2.6379e-03,  9.7607e-03,  5.8711e-03,  1.2601e-02,\n",
      "          1.4659e-02, -7.3646e-03,  4.5020e-03,  7.6478e-03,  1.3880e-02,\n",
      "          7.9266e-04,  2.8378e-03, -3.9424e-03,  1.1628e-02,  1.1834e-02,\n",
      "          3.8579e-03, -5.2197e-03,  3.9044e-03,  1.4622e-02,  1.2391e-02,\n",
      "         -2.5109e-03,  9.1217e-03, -6.5019e-03,  1.5358e-02,  3.0553e-03,\n",
      "          1.0773e-02, -8.2021e-03, -6.1847e-03,  6.1815e-03,  1.0959e-02,\n",
      "          1.2326e-02, -4.7963e-03,  7.2879e-03,  6.8363e-03,  5.7396e-03,\n",
      "          1.5067e-02,  1.2966e-02,  1.0611e-02,  1.2205e-02,  8.2923e-03,\n",
      "          3.5299e-03, -7.0572e-04, -7.1069e-03, -7.6627e-03, -7.9391e-03,\n",
      "          1.0158e-02,  1.4036e-02, -1.4346e-03,  1.1321e-02,  6.0164e-03,\n",
      "         -9.7585e-04, -6.4335e-03, -8.3971e-03, -2.9857e-03,  1.5975e-02,\n",
      "          8.6908e-03,  8.6666e-05, -4.4313e-03,  4.2475e-03,  9.8739e-03,\n",
      "          4.3210e-03,  8.4936e-03,  7.5330e-03,  1.5418e-02, -5.3839e-03,\n",
      "          1.0056e-02,  6.2515e-03, -4.1510e-03, -3.9110e-03, -4.5626e-03,\n",
      "         -3.9781e-03,  1.1697e-02,  1.5611e-02, -2.4220e-03,  2.3382e-03,\n",
      "          1.1106e-02, -1.1912e-03,  8.5224e-03, -2.7978e-03, -1.8831e-03,\n",
      "          6.1454e-03, -3.2036e-03,  1.5280e-02,  1.0941e-02, -1.4799e-03,\n",
      "          4.5083e-03, -6.9735e-03, -3.2106e-04,  1.1504e-03, -8.9258e-03,\n",
      "         -3.6994e-03, -1.6826e-03, -8.6529e-03, -5.2858e-03, -7.8364e-03,\n",
      "          1.2481e-03,  4.9609e-03,  1.1508e-02,  8.4806e-03,  4.7536e-03]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  value[~valid]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 1000), grad_fn=<IndexBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.max(value[~valid], dim=-1)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** RuntimeError: cannot perform reduction function max on tensor with no elements because the operation does not have an identity\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  value[~valid]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 1000), grad_fn=<IndexBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  value[~valid, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 1000), grad_fn=<IndexBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit()\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb4bf5-ad3b-495c-aab2-7c12d101c4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
