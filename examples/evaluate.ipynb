{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b4f12b-eba5-45db-9813-b8ac920b1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.macbf import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6b4d8-20a5-4398-8576-01bec78620e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf0fd485-7b39-412d-9330-7197c002b586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.12 0.08333333333333333 1.0 39.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.96 0.6533333333333333 1.0 67.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.98 0.7066666666666667 0.99 76.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:47<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.98 0.7566666666666667 1.0 74.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:51<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.99 0.77 0.99 82.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "from models import *   \n",
    "from core import generate_default_model_name\n",
    "import pickle as pkl\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "SAVE_GIF = False\n",
    "ONLY_SHOW_COLLIDE = True\n",
    "VERBOSE = False\n",
    "\n",
    "dataset_mode = 'static'\n",
    "\n",
    "for density in [0,5,10,15,20]:\n",
    "\n",
    "    with open(f'dataset/{project_name}_{dataset_mode}_{density}.pkl', 'rb') as f:\n",
    "        valid_dataset = pkl.load(f)\n",
    "\n",
    "    bnn = create_network()\n",
    "    bnn.load_state_dict(torch.load(BMODEL_PATH, map_location=device))\n",
    "    bnn.eval();\n",
    "\n",
    "    import copy\n",
    "\n",
    "    collideds = []\n",
    "    dones = []\n",
    "    lengths = []\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    path = f'gifs/0513/{project_name}_{version_name}/{density}'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    for v_idx in tqdm(range(len(valid_dataset))):\n",
    "        data = valid_dataset[v_idx]\n",
    "        env = create_env(num_agents=3, size=4, max_dist=1, density=0)\n",
    "        env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "        if project_name=='drone':\n",
    "            env.world.agents[:, 3:6] = 0\n",
    "        if SAVE_GIF:\n",
    "            gif_file = f'gifs/0513/{project_name}_{version_name}/{density}/'+str(v_idx)+f'_decompose_lie.gif'\n",
    "        else:\n",
    "            gif_file = None\n",
    "        collided, done, path = infer(env,bnn,verbose=VERBOSE,n_action=10000,\n",
    "                                     max_episode_length=512,\n",
    "                                     spatial_prop=False,lie_derive_safe=False,decompose='random',\n",
    "                                     stop_at_collision=False,need_gif=gif_file)\n",
    "        collideds.append(collided)\n",
    "        dones.append(done)\n",
    "        lengths.append(len(path))\n",
    "        paths.append(path)\n",
    "\n",
    "    print(density, np.any(collideds, axis=-1).mean(), np.mean(collideds), np.mean(dones), np.mean(lengths))\n",
    "\n",
    "    with open(f'results/{project_name}_{version_name}_{dataset_mode}_{density}.pkl', 'wb') as f:\n",
    "        pkl.dump({'collideds': collideds,\n",
    "                  'dones': dones,\n",
    "                  'lengths': lengths,\n",
    "                  'paths': paths}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ab6ff-949b-45a7-a3f4-086e514c150b",
   "metadata": {},
   "source": [
    "# Evaluate Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebac237-a0a3-4226-b48a-5237f1f5ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:32<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.67 0.67 1.0 58.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:58<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1.0 0.7933333333333333 1.0 94.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:55<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 1.0 0.87625 0.95 154.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:33<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 1.0 0.874375 0.86 230.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:29<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 1.0 0.888125 0.87 265.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [11:10<00:00,  6.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 1.0 0.88484375 0.65 361.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [21:17<00:00, 12.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 1.0 0.88203125 0.53 411.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [47:16<00:00, 28.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 1.0 0.8859375 0.27 482.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:15<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.14 0.14 0.03 500.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:59<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.49 0.23666666666666666 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:08<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.97 0.34625 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:38<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.99 0.390625 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:22<00:00,  6.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 1.0 0.4428125 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [15:34<00:00,  9.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 1.0 0.455625 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [26:07<00:00, 15.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 1.0 0.472265625 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [49:20<00:00, 29.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 1.0 0.49328125 0.0 513.0\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "from models import *   \n",
    "from core import generate_default_model_name\n",
    "import pickle as pkl\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "for method_id in [1,2]:\n",
    "    if method_id == 1:\n",
    "        from baselines.macbf import *\n",
    "    elif method_id == 2:\n",
    "        from baselines.ddpg import *\n",
    "    elif method_id == 3:\n",
    "        from drone_v34 import *\n",
    "\n",
    "    dataset_mode = 'dynamic'\n",
    "\n",
    "    for density in [1,3]+list(2**np.arange(3, 9)):  # \n",
    "\n",
    "        with open(f'dataset/{project_name}_{dataset_mode}_{density}.pkl', 'rb') as f:\n",
    "            valid_dataset = pkl.load(f)\n",
    "\n",
    "        bnn = create_network()\n",
    "        bnn.load_state_dict(torch.load(BMODEL_PATH, map_location=device))\n",
    "        bnn.eval();\n",
    "\n",
    "        import copy\n",
    "\n",
    "        collideds = []\n",
    "        dones = []\n",
    "        lengths = []\n",
    "\n",
    "        paths = []\n",
    "\n",
    "        path = f'gifs/0513/{project_name}_{version_name}/{density}'\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        for v_idx in tqdm(range(len(valid_dataset))):\n",
    "            data = valid_dataset[v_idx]\n",
    "            env = create_env(num_agents=density, size = int((density*16)**0.5), max_dist=1, density=0)\n",
    "            env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "            if project_name=='drone':\n",
    "                env.world.agents[:, 3:6] = 0\n",
    "            gif_file = None\n",
    "            collided, done, path = infer(env,bnn,seed=v_idx,bnn=bnn,verbose=VERBOSE,n_action=10000,\n",
    "                                         max_episode_length=512,\n",
    "                                         spatial_prop=False,lie_derive_safe=False,decompose='random',\n",
    "                                         stop_at_collision=False,need_gif=gif_file)\n",
    "            collideds.append(collided)\n",
    "            dones.append(done)\n",
    "            lengths.append(len(path))\n",
    "            paths.append(path)\n",
    "\n",
    "        print(density, np.any(collideds, axis=-1).mean(), np.mean(collideds), np.mean(dones), np.mean(lengths))\n",
    "\n",
    "        with open(f'results/{project_name}_{version_name}_{dataset_mode}_{density}.pkl', 'wb') as f:\n",
    "            pkl.dump({'collideds': collideds,\n",
    "                      'dones': dones,\n",
    "                      'lengths': lengths,\n",
    "                      'paths': paths}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d2abb-4da4-4839-a37c-b3f3541f43bf",
   "metadata": {},
   "source": [
    "# Evaluate Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8cb1ae-6c4e-48b1-8344-2036d55c6f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:40<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "from models import *   \n",
    "from core import generate_default_model_name\n",
    "import pickle as pkl\n",
    "import os\n",
    "from baselines.ddpg import *\n",
    "\n",
    "if project_name == 'multi_dynamic':\n",
    "    project_name = 'multi_dynamic_dubins'\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "size = 32\n",
    "dataset_mode = 'mixed'\n",
    "decompose = None\n",
    "\n",
    "for density in list([1,3]+list(2**np.arange(3, 10)))[-1:]:\n",
    "\n",
    "    with open(f'dataset/{project_name}_{dataset_mode}_{density}.pkl', 'rb') as f:\n",
    "        valid_dataset = pkl.load(f)\n",
    "\n",
    "    bnn = create_network()\n",
    "    bnn.load_state_dict(torch.load(BMODEL_PATH, map_location=device))\n",
    "    bnn.eval();\n",
    "\n",
    "    import copy\n",
    "\n",
    "    collideds = []\n",
    "    dones = []\n",
    "    lengths = []\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    path = f'gifs/0513/{project_name}_{version_name}/{density}'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    for v_idx in tqdm(range(len(valid_dataset))):\n",
    "        data = valid_dataset[v_idx]\n",
    "        env = create_env(num_agents=density, size = size, max_dist=1, density=0)\n",
    "        env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "        if project_name=='drone':\n",
    "            env.world.agents[:, 3:6] = 0\n",
    "        gif_file = None\n",
    "        collided, done, path = infer(env,bnn,verbose=False,n_action=2000,\n",
    "                                     max_episode_length=512,\n",
    "                                     spatial_prop=False,lie_derive_safe=False,decompose=decompose,\n",
    "                                     stop_at_collision=False,need_gif=gif_file)\n",
    "        collideds.append(collided)\n",
    "        dones.append(done)\n",
    "        lengths.append(len(path))\n",
    "        paths.append(path)\n",
    "\n",
    "    print(density, np.any(collideds, axis=-1).mean(), np.mean(collideds), np.mean(dones), np.mean(lengths))\n",
    "\n",
    "    suffix = '' if decompose=='random' else 'no_decompose_'\n",
    "    with open(f'results/{project_name}_{version_name}_{suffix}{dataset_mode}_{density}.pkl', 'wb') as f:\n",
    "        pkl.dump({'collideds': collideds,\n",
    "                  'dones': dones,\n",
    "                  'lengths': lengths,\n",
    "                  'paths': paths}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c52e651-1552-4b03-a74f-38836f5ac00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:08<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.03 0.03 0.85 153.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:52<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.15 0.056666666666666664 0.63 280.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:02<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.43 0.0625 0.29 415.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:26<00:00,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.65 0.061875 0.08 487.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:40<00:00,  6.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 0.84 0.0715625 0.01 510.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [16:35<00:00,  9.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 0.98 0.083125 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [29:07<00:00, 17.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 1.0 0.105390625 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [54:58<00:00, 32.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 1.0 0.155390625 0.0 513.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:40:46<00:00, 60.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 1.0 0.265703125 0.0 513.0\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "from models import *   \n",
    "from core import generate_default_model_name\n",
    "import pickle as pkl\n",
    "import os\n",
    "# from v109 import *\n",
    "from v0_multi_dynamic_dubins import *\n",
    "from baselines.ddpg import *\n",
    "\n",
    "if project_name == 'multi_dynamic':\n",
    "    project_name = 'multi_dynamic_dubins'\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "size = 32\n",
    "dataset_mode = 'mixed'\n",
    "decompose = 'random'\n",
    "\n",
    "for density in [1,3]+list(2**np.arange(3, 10)):\n",
    "\n",
    "    with open(f'dataset/{project_name}_{dataset_mode}_{density}.pkl', 'rb') as f:\n",
    "        valid_dataset = pkl.load(f)\n",
    "\n",
    "    bnn = create_network()\n",
    "    bnn.load_state_dict(torch.load(BMODEL_PATH, map_location=device))\n",
    "    bnn.eval();\n",
    "\n",
    "    import copy\n",
    "\n",
    "    collideds = []\n",
    "    dones = []\n",
    "    lengths = []\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    path = f'gifs/0513/{project_name}_{version_name}/{density}'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    for v_idx in tqdm(range(len(valid_dataset))):\n",
    "        data = valid_dataset[v_idx]\n",
    "        env = create_env(num_agents=density, size = size, max_dist=1, density=0)\n",
    "        env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "        if project_name=='drone':\n",
    "            env.world.agents[:, 3:6] = 0\n",
    "        gif_file = None\n",
    "        collided, done, path = infer(env,bnn,verbose=False,n_action=10000,\n",
    "                                     max_episode_length=512,\n",
    "                                     spatial_prop=False,lie_derive_safe=False,decompose=decompose,\n",
    "                                     stop_at_collision=False,need_gif=gif_file)\n",
    "        collideds.append(collided)\n",
    "        dones.append(done)\n",
    "        lengths.append(len(path))\n",
    "        paths.append(path)\n",
    "\n",
    "    print(density, np.any(collideds, axis=-1).mean(), np.mean(collideds), np.mean(dones), np.mean(lengths))\n",
    "\n",
    "    suffix = '' if decompose=='random' else 'no_decompose_'\n",
    "    with open(f'results/{project_name}_{version_name}_{suffix}{dataset_mode}_{density}.pkl', 'wb') as f:\n",
    "        pkl.dump({'collideds': collideds,\n",
    "                  'dones': dones,\n",
    "                  'lengths': lengths,\n",
    "                  'paths': paths}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bfbc25-5190-48d8-a6c8-e33eaa6293a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0217_grid_Q.json2\n",
      " 0512.txt\n",
      " 1.txt\n",
      " 1model_DroneEnv.txt\n",
      " 1model_DubinsCarEnv_v78.txt\n",
      " Certificate_Exploration.ipynb\n",
      " Certificate_OneModel-Pure.ipynb\n",
      " Certificate_OneModel_Warmup.ipynb\n",
      " Inference_Barrier_Drone.ipynb\n",
      " Inference_Barrier_Drone_Decompose.ipynb\n",
      " Inference_Barrier_Dubins.ipynb\n",
      " Inference_Barrier_Dubins_Decompose.ipynb\n",
      " Inference_Barrier_Dubins_old.ipynb\n",
      " Inference_Barrier_MultiPoint.ipynb\n",
      " Inference_Barrier_Point.ipynb\n",
      " Inference_Barrier_PointEnv.ipynb\n",
      " Inference_Barrier_Swimmer.ipynb\n",
      " Inference_Barrier_UR5Env.ipynb\n",
      " Inference_DynamicDubins.ipynb\n",
      " Inference_Lya_Drone.ipynb\n",
      " Q_vs_CLF.ipynb\n",
      " Train_Barrier_Dubins.ipynb\n",
      " Train_Barrier_MultiPoint-FixObstacle.ipynb\n",
      " Train_Barrier_MultiPoint.ipynb\n",
      " __init__.py\n",
      " __pycache__\n",
      " a.png\n",
      " arm_env.py\n",
      " arm_env2.py\n",
      " arrow_boundary.pdf\n",
      " azhe1.pdf\n",
      " azhe2.pdf\n",
      " baselines\n",
      " calculate_stats.py\n",
      " cam.gif\n",
      " chasing.txt\n",
      " check_rl_swimmer.ipynb\n",
      " configs\n",
      " core.py\n",
      " count_experience.ipynb\n",
      " count_subgraph.ipynb\n",
      " dataset\n",
      " dataset_copy\n",
      " drone.gif\n",
      " drone_env.py\n",
      " drone_v0.py\n",
      " drone_v20.py\n",
      " drone_v23.py\n",
      " drone_v24.py\n",
      " drone_v28.py\n",
      " drone_v34.py\n",
      " dubins2.gif\n",
      " dubins_decompose.pkl\n",
      " dynamic_dubins.pdf\n",
      " dynamic_dubins.py\n",
      " environment\n",
      " evaluate.ipynb\n",
      " evaluate_jeff.ipynb\n",
      " evaluate_ur5.ipynb\n",
      " filter_best_dubins.ipynb\n",
      " generate_dataset.py\n",
      " generate_result_data.ipynb\n",
      " gg.gif\n",
      " gifs\n",
      " grid-world.ipynb\n",
      " gym_dubins_car.py\n",
      " gym_multi_point-Copy1.py\n",
      " gym_multi_point.py\n",
      " gym_point.py\n",
      " gym_swimmer.py\n",
      " infer_multi_single.py\n",
      " inference.py\n",
      " inference_drone.py\n",
      " inference_multi_dynamic_dubins.py\n",
      " inference_time.ipynb\n",
      " inference_ur5.py\n",
      " landscape.ipynb\n",
      " landscape.pdf\n",
      " landscape2.pdf\n",
      " landscape3.pdf\n",
      " logs\n",
      " lya_1phase.gif\n",
      " lya_2phase.gif\n",
      " lya_cam.gif\n",
      " lya_cam_fail.gif\n",
      " lya_cam_success.gif\n",
      " lya_uniform.gif\n",
      " lya_uniform_fail.gif\n",
      " lya_uniform_success.gif\n",
      " model_gnn\n",
      " models.py\n",
      " modern.py\n",
      " off_policy.py\n",
      " output.mp4\n",
      " output2.mp4\n",
      " play.gif\n",
      " playground\n",
      " point_env.py\n",
      " point_env2.py\n",
      " point_env_buffer_update.py\n",
      " potential_field.py\n",
      " results\n",
      " results_copy\n",
      " rl.gif\n",
      " rl.py\n",
      " runs\n",
      " shit.gif\n",
      " single_max.pdf\n",
      " single_min.pdf\n",
      " single_volume.pdf\n",
      " swimmer\n",
      " swimmer.ipynb\n",
      " swimmer.xml\n",
      " swimmer_cam.gif\n",
      " temp.json\n",
      "'test (1).ipynb'\n",
      " test.ipynb\n",
      " test_drone.ipynb\n",
      " test_mujoco.ipynb\n",
      " train_barrier_dubins.py\n",
      " train_barrier_multi_point.py\n",
      " train_barrier_point.py\n",
      " train_barrier_swimmer.py\n",
      " train_dubins.py\n",
      " train_dubins_no_obstacle.py\n",
      " train_dubins_no_obstacle_old.py\n",
      " train_dubins_no_obstacle_origin_arch.py\n",
      " train_dubins_no_obstacle_v1.py\n",
      " train_dubins_no_obstacle_v14.py\n",
      " train_dubins_no_obstacle_v15.py\n",
      " train_dubins_no_obstacle_v16.py\n",
      " train_dubins_no_obstacle_v17.py\n",
      " train_dubins_no_obstacle_v18.py\n",
      " train_dubins_no_obstacle_v19.py\n",
      " train_dubins_no_obstacle_v2.py\n",
      " train_dubins_no_obstacle_v20.py\n",
      " train_dubins_no_obstacle_v21.py\n",
      " train_dubins_no_obstacle_v3.py\n",
      " train_dubins_no_obstacle_v4.py\n",
      " train_dubins_random_dataset.py\n",
      " train_dubins_with_obstacle_clf.py\n",
      " train_dubins_with_obstacle_reproduce.py\n",
      " train_dubins_with_obstacle_v10.py\n",
      " train_dubins_with_obstacle_v11.py\n",
      " train_dubins_with_obstacle_v12.py\n",
      " train_dubins_with_obstacle_v13.py\n",
      " train_dubins_with_obstacle_v22.py\n",
      " train_dubins_with_obstacle_v23.py\n",
      " train_dubins_with_obstacle_v24.py\n",
      " train_dubins_with_obstacle_v26.py\n",
      " train_dubins_with_obstacle_v5.py\n",
      " train_dubins_with_obstacle_v6.py\n",
      " train_dubins_with_obstacle_v7.py\n",
      " train_dubins_with_obstacle_v8.py\n",
      " train_dubins_with_obstacle_v9.py\n",
      " train_lya_drone.py\n",
      " train_multi_fix_start.py\n",
      " train_multi_no_obstacle.py\n",
      " train_multi_single_fix_obstacle.py\n",
      " train_multi_single_random_dataset.py\n",
      " train_multi_single_random_dataset_clbf.py\n",
      " train_multi_single_random_dataset_good.py\n",
      " train_multi_single_random_dataset_v2.py\n",
      " train_multi_single_random_dataset_v3.py\n",
      " train_multi_single_random_dataset_v4.py\n",
      " try.py\n",
      " v0_multi_dynamic_dubins.py\n",
      " v109.py\n",
      " v124.py\n",
      " v31.py\n",
      " v78.py\n",
      " v79.py\n",
      " visualize.ipynb\n",
      " visualize_all_envs.ipynb\n",
      " visualize_chasing.ipynb\n",
      " visualize_drone.ipynb\n",
      " visualize_landscape.ipynb\n",
      " wandb\n",
      " why.gif\n",
      " widget\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccd637-8b2c-417e-9d1e-8587be8e3a20",
   "metadata": {},
   "source": [
    "# Generate An Example Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc1a3c2-a062-42cb-9d52-37e52d186ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------env created-----------\n"
     ]
    }
   ],
   "source": [
    "env = create_env(num_agents=2048, size=64, max_dist=16, density=10)\n",
    "print('----------env created-----------')\n",
    "if project_name=='drone':\n",
    "    env.world.agents[:, 3:6] = 0\n",
    "gif_file = None\n",
    "collided, done, path = infer(env,bnn,verbose=False,n_action=10000,\n",
    "                             max_episode_length=1024,\n",
    "                             spatial_prop=False,lie_derive_safe=False,decompose='random',\n",
    "                             stop_at_collision=False,need_gif=gif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea3c0ae-7ff2-4547-9121-aca42db539b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/drone_2048.pkl', 'wb') as f:\n",
    "    pkl.dump([env.world.obstacles, env.world.agent_goals, path], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ae838-dd16-4001-ace2-2ebfd8b2578f",
   "metadata": {},
   "source": [
    "# Chasing Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71e52e4c-03e0-4af8-bb51-9220e30869f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from drone_v34 import *\n",
    "import os\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_chase(env, bnn, threshold=None, max_episode_length=256, \n",
    "          n_action=None,\n",
    "          verbose=False, seed=0, stop_at_collision=False, \n",
    "          spatial_prop=None, need_gif=None, \n",
    "          decompose=None, lie_derive_safe=None,\n",
    "          only_show_collide=False):\n",
    "    \n",
    "    if spatial_prop is None:\n",
    "        spatial_prop = SPATIAL_PROP\n",
    "        \n",
    "    if n_action is None:\n",
    "        n_action = n_candidates\n",
    "        \n",
    "    if lie_derive_safe is None:\n",
    "        lie_derive_safe = LIE_DERIVE_SAFE\n",
    "    \n",
    "    if threshold is None:\n",
    "        threshold=THRESHOLD\n",
    "    if verbose:\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    goal_agent_idx = (np.array(range(env.num_agents))-1)%env.num_agents\n",
    "    dist_goal = np.array(env.world.agents[:,:env.space_dim]-env.world.agents[goal_agent_idx,:env.space_dim])\n",
    "    dist_goal = np.linalg.norm(dist_goal, axis=-1)\n",
    "    paths = [deepcopy(env.world.agents)]\n",
    "    total_trans=0; n_danger=0; \n",
    "    no_feasible=0; collided=np.zeros(env.num_agents).astype(bool); thresholds=np.array([threshold]*env.num_agents)\n",
    "    reward = 0\n",
    "    \n",
    "    while True:  \n",
    "        env.world.agent_goals[:,:env.space_dim] = env.world.agents[goal_agent_idx,:env.space_dim]        \n",
    "        \n",
    "        a, v, feasibles, evil_agents = choose_action(bnn=bnn, env=env, explore_eps=0, \n",
    "                                                     nominal_eps=0, \n",
    "                                                     spatial_prop=spatial_prop, \n",
    "                                                     thresholds=thresholds,\n",
    "                                                     n_action=n_action,\n",
    "                                                     decompose=decompose)\n",
    "        next_o, rw, done, info = env.step(a, obs_config=OBS_CONFIG)\n",
    "        env.world.agent_goals[:,:env.space_dim] = env.world.agents[goal_agent_idx,:env.space_dim]   \n",
    "        \n",
    "        prev_danger = info['prev_danger'].data.cpu().numpy().astype(bool)\n",
    "        next_danger = info['next_danger'].data.cpu().numpy().astype(bool)\n",
    "        if np.any(next_danger):\n",
    "            collided = collided | next_danger\n",
    "            n_danger = n_danger + np.sum(next_danger)\n",
    "        if verbose:\n",
    "            print(total_trans, v.min(axis=-1), v.max(axis=-1), np.where(v<=thresholds), np.where(next_danger), evil_agents)\n",
    "            \n",
    "        total_trans += 1\n",
    "        if lie_derive_safe:\n",
    "            thresholds = 0.9*v+1e-2\n",
    "        dist_goal_current = np.array(env.world.agents[:,:env.space_dim]-env.world.agents[goal_agent_idx,:env.space_dim])\n",
    "        dist_goal_current = np.linalg.norm(dist_goal_current, axis=-1)\n",
    "        reward += (dist_goal - dist_goal_current).clip(0, 2).mean()\n",
    "        reward -= next_danger.sum() / env.num_agents\n",
    "        dist_goal = dist_goal_current\n",
    "        \n",
    "        paths.append(deepcopy(env.world.agents))\n",
    "\n",
    "        if np.any(next_danger) and stop_at_collision:\n",
    "            break        \n",
    "        \n",
    "        if done or (total_trans >= max_episode_length):\n",
    "            break\n",
    "            \n",
    "    if (need_gif is not None):\n",
    "        if (not only_show_collide) or (np.any(collided)):\n",
    "            env.save_fig(paths, 1000*np.ones((env.num_agents, env.state_dim)), env.world.obstacles, need_gif[:-4]+'_'+str(np.any(collided))+'_'+str(done)+need_gif[-4:])\n",
    "\n",
    "    safety_rate = 1 -(n_danger / (total_trans * env.num_agents))\n",
    "            \n",
    "    return collided, done, safety_rate, reward, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ec68fd8-6c91-4269-b952-1cc12ebe8f15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "100%|██████████| 10/10 [00:55<00:00,  5.52s/it]\n",
      "100%|██████████| 10/10 [03:40<00:00, 22.04s/it]\n",
      "100%|██████████| 10/10 [14:10<00:00, 85.02s/it]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.23it/s]\n",
      "100%|██████████| 10/10 [00:29<00:00,  2.90s/it]\n",
      "100%|██████████| 10/10 [01:26<00:00,  8.63s/it]\n",
      "100%|██████████| 10/10 [05:19<00:00, 31.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# drone\n",
    "from drone_v34 import *\n",
    "bnn = create_network()\n",
    "bnn.load_state_dict(torch.load(BMODEL_PATH, map_location=device))\n",
    "bnn.eval()\n",
    "\n",
    "collideds = []\n",
    "dones = []\n",
    "lengths = []\n",
    "paths = []\n",
    "path = f'gifs/0604/drone/chasing.mp4'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "for decompose in ['random', None]:\n",
    "    for num_agents in [3,16,64,256]:\n",
    "\n",
    "        safety_rates = []\n",
    "        rewards = []\n",
    "        for seed in tqdm([0, 100, 200, 300, 400, 500, 600, 700, 800, 900]):\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            env = create_env(num_agents=num_agents, size=max(3, int(2*num_agents**0.5)), min_dist=0, max_dist=2000)\n",
    "            env.world.agents[:,6:] = 0\n",
    "            collided, done, safety_rate, reward, paths = infer_chase(env,bnn,verbose=False,n_action=2000,\n",
    "                  max_episode_length=256, spatial_prop=False, seed=seed,\n",
    "                  lie_derive_safe=False, decompose=decompose, stop_at_collision=False,need_gif=None)\n",
    "            safety_rates.append(safety_rate)\n",
    "            rewards.append(reward)\n",
    "        with open('chasing.txt', 'a') as f:\n",
    "            f.write(str(('drone', decompose, num_agents, np.mean(safety_rates), np.mean(rewards), np.std(safety_rates), np.std(rewards))).strip('()')+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5eb9900b-bcf2-48b1-bfbd-88b5e072e2e3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n",
      "100%|██████████| 10/10 [03:29<00:00, 20.98s/it]\n",
      "100%|██████████| 10/10 [16:08<00:00, 96.83s/it]\n",
      "100%|██████████| 10/10 [1:04:56<00:00, 389.69s/it]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "100%|██████████| 10/10 [00:36<00:00,  3.63s/it]\n",
      "100%|██████████| 10/10 [02:04<00:00, 12.46s/it]\n",
      "100%|██████████| 10/10 [07:54<00:00, 47.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# car\n",
    "from v109 import *\n",
    "bnn = create_network()\n",
    "bnn.load_state_dict(torch.load(BMODEL_PATH, map_location=device))\n",
    "bnn.eval()\n",
    "\n",
    "collideds = []\n",
    "dones = []\n",
    "lengths = []\n",
    "paths = []\n",
    "path = f'gifs/0604/drone/chasing.mp4'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "for decompose in ['random', None]:\n",
    "    for num_agents in [3,16,64,256]:\n",
    "\n",
    "        safety_rates = []\n",
    "        rewards = []\n",
    "        for seed in tqdm([0, 100, 200, 300, 400, 500, 600, 700, 800, 900]):\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            env = create_env(num_agents=num_agents, size=max(3, int(num_agents**0.5)), min_dist=2, max_dist=10000)\n",
    "            collided, done, safety_rate, reward, paths = infer_chase(env,bnn,verbose=False,n_action=2000,\n",
    "                  max_episode_length=256, spatial_prop=False, seed=seed,\n",
    "                  lie_derive_safe=False, decompose=decompose, stop_at_collision=False,need_gif=None)\n",
    "            safety_rates.append(safety_rate)\n",
    "            rewards.append(reward)\n",
    "        with open('chasing.txt', 'a') as f:\n",
    "            f.write(str(('car', decompose, num_agents, np.mean(safety_rates), np.mean(rewards), np.std(safety_rates), np.std(rewards))).strip('()')+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
