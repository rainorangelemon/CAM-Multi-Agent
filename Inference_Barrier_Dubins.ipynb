{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae806caa-df39-46e4-b8b7-2ce16413800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712be4ab-10a5-4f04-9bb6-27aca9e00010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "from models import *   \n",
    "from v109 import *\n",
    "from core import generate_default_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cff570-de65-4e79-b3fc-565efa0fd8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.tensor(np.array([1,2,3.])).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2161242-1a0a-48c7-bca9-7608709fc23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974da2e1-b887-4533-8ee7-9708f56f65fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rainorangelemon/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/nn/modules/lazy.py:175: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "Env = DubinsCarEnv\n",
    "env = DubinsCarEnv(num_agents=3, PROB=(0,0.1), SIZE=(8,8))\n",
    "\n",
    "bnn = create_network()\n",
    "print(bnn.load_state_dict(torch.load('model_gnn/dbgnn_DubinsCarEnv_v115_65.pt', map_location=device)))\n",
    "bnn.eval();\n",
    "# BMODEL_PATH\n",
    "# BMODEL_PATH.replace('.pt', \"_current.pt\")\n",
    "# BMODEL_PATH.replace('.pt', \"_warmup.pt\")\n",
    "# BMODEL_PATH.replace('_'+version_name+'.pt', '_v22.pt')\n",
    "# 'model_gnn/dbgnn_DubinsCarEnv13199_0.00.pt'\n",
    "# 'model_gnn/dbgnn_DubinsCarEnv_v133999.pt'\n",
    "# 'model_gnn/good_models/dbgnn_DubinsCarEnv_v114_66.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b613ee-5306-47f7-b849-b2555717d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMODEL_PATH.replace('.pt', \"_current.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221df3a9-36c0-4530-badd-29988a8da744",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTS, OBSTACLE_DENSITY, MAP_SIZE = 8, 1.0, 4\n",
    "\n",
    "valid_dataset = []\n",
    "for _ in range(100):\n",
    "    # while True:\n",
    "    env = create_env()\n",
    "    valid_dataset.append((env.world.obstacles.copy(), env.world.agent_goals.copy(), env.world.agents.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00989997-455b-42ed-9625-117f5420814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.flatten(torch.randn(2, 3), start_dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af91a10-c7a4-4c38-8a4d-f27f38390360",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "collideds = []\n",
    "dones = []\n",
    "lengths = []\n",
    "for v_idx, data in tqdm(enumerate(valid_dataset)):\n",
    "    env = create_env()\n",
    "    env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "    # env.world.agents[1:,:]=-100\n",
    "    # env.world.obstacles = [[1.499, 1.499]]\n",
    "    collided, done, gifs = infer(env,bnn,verbose=False,spatial_prop=False,stop_at_collision=True)\n",
    "    save_gif(gifs, 'gifs/0416/v115/'+str(v_idx)+'_'+str(np.any(collided))+'_'+str(done)+'.gif')\n",
    "    collideds.append(collided)\n",
    "    dones.append(done)\n",
    "    lengths.append(len(gifs))\n",
    "    \n",
    "print(np.mean(collideds), np.mean(dones), np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d42e91-e9b1-47f1-a52a-da2d5f3451f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396296cc-37d0-4f4e-8be3-1ec4634a2041",
   "metadata": {},
   "source": [
    "# generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ab9e04-55b9-43d5-9587-1f1a783adeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = []\n",
    "for _ in range(1):\n",
    "    # while True:\n",
    "    # env = create_env(num_agents=2048, size=64)\n",
    "    env = create_env(num_agents=2048, size=64)\n",
    "    valid_dataset.append((env.world.obstacles.copy(), env.world.agent_goals.copy(), env.world.agents.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01fd5c4-0f2d-4e60-bb62-9514eb147387",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [20:07, 1207.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05908203125 0.0 1001.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collideds = []\n",
    "dones = []\n",
    "lengths = []\n",
    "for v_idx, data in tqdm(enumerate(valid_dataset)):\n",
    "    env = create_env(num_agents=2048, size=64, density=0)\n",
    "    env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "    gif_file = 'gifs/0416/v115/2048_'+str(v_idx)+'.mp4'\n",
    "    collided, done, gifs = infer(env,bnn,max_episode_length=1000,threshold=5e-2,verbose=False,spatial_prop=False,stop_at_collision=False,need_gif=None)\n",
    "    collideds.append(collided)\n",
    "    dones.append(done)\n",
    "    lengths.append(len(gifs))\n",
    "    \n",
    "print(np.mean(collideds), np.mean(dones), np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58627f47-a93c-49cf-9434-7e9a774c9113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [23:56, 1436.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05908203125 0.0 1001.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collideds = []\n",
    "dones = []\n",
    "lengths = []\n",
    "for v_idx, data in tqdm(enumerate(valid_dataset)):\n",
    "    env = create_env(num_agents=2048, size=64, density=0)\n",
    "    env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "    gif_file = 'gifs/0416/v115/2048_'+str(v_idx)+'.mp4'\n",
    "    collided, done, gifs = infer(env,bnn,max_episode_length=1000,threshold=5e-2,verbose=False,spatial_prop=False,stop_at_collision=False,need_gif=None)\n",
    "    collideds.append(collided)\n",
    "    dones.append(done)\n",
    "    lengths.append(len(gifs))\n",
    "    \n",
    "print(np.mean(collideds), np.mean(dones), np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb3cbeb-504e-4519-b748-7a075790dbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [20:16, 1216.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12353515625 0.0 1001.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collideds = []\n",
    "dones = []\n",
    "lengths = []\n",
    "for v_idx, data in tqdm(enumerate(valid_dataset)):\n",
    "    env = create_env(num_agents=2048, size=64, density=0)\n",
    "    env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "    gif_file = 'gifs/0416/v115/2048_'+str(v_idx)+'.mp4'\n",
    "    collided, done, gifs = infer(env,bnn,max_episode_length=1000,threshold=3e-2,verbose=False,spatial_prop=False,stop_at_collision=False,need_gif=None)\n",
    "    collideds.append(collided)\n",
    "    dones.append(done)\n",
    "    lengths.append(len(gifs))\n",
    "    \n",
    "print(np.mean(collideds), np.mean(dones), np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d43bc-76cc-41dc-97c7-982cd2571158",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82766291-208d-42db-a258-f95435269f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "\n",
    "plt.clf()\n",
    "plt.close('all')\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "# Create new Figure and an Axes which fills it.\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_axes([0, 0, 1, 1], frameon=False)\n",
    "ax.set_xlim(0, 1), ax.set_xticks([])\n",
    "ax.set_ylim(0, 1), ax.set_yticks([])\n",
    "\n",
    "# Create rain data\n",
    "n_drops = 50\n",
    "rain_drops = np.zeros(n_drops, dtype=[('position', float, 2),\n",
    "                                      ('size',     float, 1),\n",
    "                                      ('growth',   float, 1),\n",
    "                                      ('color',    float, 4)])\n",
    "\n",
    "# Initialize the raindrops in random positions and with\n",
    "# random growth rates.\n",
    "rain_drops['position'] = np.random.uniform(0, 1, (n_drops, 2))\n",
    "rain_drops['growth'] = np.random.uniform(50, 200, n_drops)\n",
    "\n",
    "# Construct the scatter which we will update during animation\n",
    "# as the raindrops develop.\n",
    "scat = ax.scatter(rain_drops['position'][:, 0], rain_drops['position'][:, 1],\n",
    "                  s=rain_drops['size'], lw=0.5, edgecolors=rain_drops['color'],\n",
    "                  facecolors='none')\n",
    "\n",
    "\n",
    "def update(frame_number):\n",
    "    # Get an index which we can use to re-spawn the oldest raindrop.\n",
    "    current_index = frame_number % n_drops\n",
    "\n",
    "    # Make all colors more transparent as time progresses.\n",
    "    rain_drops['color'][:, 3] -= 1.0/len(rain_drops)\n",
    "    rain_drops['color'][:, 3] = np.clip(rain_drops['color'][:, 3], 0, 1)\n",
    "\n",
    "    # Make all circles bigger.\n",
    "    rain_drops['size'] += rain_drops['growth']\n",
    "\n",
    "    # Pick a new position for oldest rain drop, resetting its size,\n",
    "    # color and growth factor.\n",
    "    rain_drops['position'][current_index] = np.random.uniform(0, 1, 2)\n",
    "    rain_drops['size'][current_index] = 5\n",
    "    rain_drops['color'][current_index] = (0, 0, 0, 1)\n",
    "    rain_drops['growth'][current_index] = np.random.uniform(50, 200)\n",
    "\n",
    "    # Update the scatter collection, with the new colors, sizes and positions.\n",
    "    scat.set_edgecolors(rain_drops['color'])\n",
    "    scat.set_sizes(rain_drops['size'])\n",
    "    scat.set_offsets(rain_drops['position'])\n",
    "\n",
    "\n",
    "# Construct the animation, using the update function as the animation director.\n",
    "animation = FuncAnimation(fig, update, frames=200, interval=10)\n",
    "f = r\"animation.mp4\" \n",
    "writermp4 = FFMpegWriter(fps=60) \n",
    "animation.save(f, writer=writermp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c86633-4f16-462d-846c-7e55d336c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(env, bnn, threshold=None, max_episode_length=256, verbose=False, seed=0, stop_at_collision=False, prop=None, need_gif=True):\n",
    "    if prop is None:\n",
    "        prop = PROP\n",
    "    \n",
    "    if threshold is None:\n",
    "        threshold=THRESHOLD\n",
    "    if verbose:\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if need_gif:\n",
    "        gifs = [env._render()]\n",
    "    else:\n",
    "        gifs = [None]\n",
    "    total_trans=0; n_danger=0; no_feasible=0; collided=np.zeros(env.num_agents).astype(bool)\n",
    "\n",
    "    while True:\n",
    "        o = env._get_obs()\n",
    "        a_all = np.random.uniform(-1, 1, size=(env.num_agents, n_candidates, env.action_dim))\n",
    "        a_refines, bvalues = eval_action(bnn, o, a_all, max_iter=0, threshold=threshold)\n",
    "\n",
    "        dists = env.potential_field(a_refines, K1=K1, K2=K2, ignore_agent=True)\n",
    "        \n",
    "        v = np.zeros(env.num_agents)\n",
    "        a = np.zeros((env.num_agents, env.action_dim))\n",
    "        evil_agents = set()\n",
    "        for agent_id, a_refine, bvalue, dist in zip(np.arange(env.num_agents), a_refines, bvalues, dists):\n",
    "            \n",
    "            feasible_current = False\n",
    "            if np.any(bvalue>threshold):\n",
    "                feasible_current = True\n",
    "            else:\n",
    "                feasible_current = False\n",
    "            \n",
    "            if feasible_current:\n",
    "                for a_idx in np.argsort(dist):\n",
    "                    if bvalue[a_idx] > threshold:\n",
    "                        a[agent_id] = a_refine[a_idx]\n",
    "                        v[agent_id] = bvalue[a_idx]\n",
    "                        break\n",
    "                continue\n",
    "            \n",
    "            if prop:\n",
    "                # find evil_agent\n",
    "                local_o = o.clone()\n",
    "                while True:\n",
    "                    local_o.to('cpu')\n",
    "                    edges = local_o['a_near_a'].edge_index\n",
    "                    neighbor_edges = edges[1]==agent_id\n",
    "                    if neighbor_edges.sum()==0:\n",
    "                        break\n",
    "\n",
    "                    first_edge = torch.where(neighbor_edges)[0][0]\n",
    "                    mask = (torch.arange(edges.shape[1])==first_edge)\n",
    "                    evil_agents.add(int(edges[0, first_edge]))\n",
    "                    local_o['a_near_a'].edge_index = edges[:,~mask]\n",
    "                    local_o['a_near_a'].edge_attr = local_o['a_near_a'].edge_attr[~mask,:]\n",
    "\n",
    "                    local_a_refines, local_bvalues = eval_action(bnn, local_o, a_all, max_iter=0, threshold=threshold)          \n",
    "                    # bvalues[agent_id] = bvalue = local_bvalues[agent_id]\n",
    "                    # a_refine = local_a_refines[agent_id]\n",
    "\n",
    "                    if np.any(local_bvalues>threshold):\n",
    "                        break\n",
    "            \n",
    "            no_feasible += 1\n",
    "            a[agent_id] = a_refine[np.argmax(bvalue)]\n",
    "            v[agent_id] = bvalue[np.argmax(bvalue)]\n",
    "                \n",
    "        for evil_agent in evil_agents:\n",
    "            a_refine, bvalue = a_refines[evil_agent], bvalues[evil_agent]\n",
    "            a[evil_agent] = a_refine[np.argmax(bvalue)]\n",
    "            v[evil_agent] = bvalue[np.argmax(bvalue)]\n",
    "\n",
    "        next_o, rw, done, info = env.step(a)\n",
    "        \n",
    "        prev_danger = info['prev_danger'].data.cpu().numpy().astype(bool)\n",
    "        next_danger = info['next_danger'].data.cpu().numpy().astype(bool)\n",
    "        if np.any(next_danger):\n",
    "            collided = collided | next_danger\n",
    "        if verbose:\n",
    "            print(total_trans, np.where(v<=threshold), next_danger, evil_agents)\n",
    "            \n",
    "        total_trans += 1\n",
    "        if need_gif:\n",
    "            gifs.append(env._render())\n",
    "        else:\n",
    "            gifs.append(None)\n",
    "\n",
    "        if np.any(next_danger) and stop_at_collision:\n",
    "            break        \n",
    "        \n",
    "        if done or (total_trans >= max_episode_length):\n",
    "            break\n",
    "\n",
    "    return collided, done, gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae9c53-91c2-42f3-8096-7f8264190656",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = create_env()\n",
    "env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(valid_dataset[17])\n",
    "_, _, gifs = infer(env, bnn, verbose=True,prop=True,stop_at_collision=True)\n",
    "save_gif(gifs, 'gifs/0406/v59/shit2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0b0c8-9036-4997-b4c3-ed1bb0432175",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.initColors()[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335ec24-b423-442c-a04c-a2b950d84cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = env._get_obs()['a_near_a'].edge_index\n",
    "edges[0,edges[1]==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a7f82-9697-41c9-a7a2-20b3914f39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset[17][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432072c-2808-4d14-8583-3aeb37bbc9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = env._get_obs()\n",
    "o = o.clone()\n",
    "\n",
    "evil_agents = []\n",
    "while True:\n",
    "    o.to('cpu')\n",
    "    agent_id = 0\n",
    "    edges = o['a_near_a'].edge_index\n",
    "    neighbor_edges = edges[1]==agent_id\n",
    "    if neighbor_edges.sum()==0:\n",
    "        break\n",
    "    \n",
    "    first_edge = torch.where(neighbor_edges)[0][0]\n",
    "    mask = (torch.arange(edges.shape[1])==first_edge)\n",
    "    evil_agents.append(int(edges[0, first_edge]))\n",
    "    o['a_near_a'].edge_index = edges[:,~mask]\n",
    "    o['a_near_a'].edge_attr = o['a_near_a'].edge_attr[~mask,:]\n",
    "\n",
    "    a_all = np.random.uniform(-1, 1, size=(env.num_agents, n_candidates, env.action_dim))\n",
    "    a_refines, bvalues = eval_action(bnn, o, a_all, max_iter=0, threshold=THRESHOLD)\n",
    "    if (bvalues[0]>THRESHOLD).any():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d3bd2-7f1a-403f-845f-0f7df5b22afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede068d-f474-40a2-aea0-d42d0e8d201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o['a_near_a'].edge_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b3ada-ae0e-40b4-91ea-1759f6bca21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.world.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42627b4-5a4b-44ef-9fb0-ae783c6f94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "batch_x = torch.tensor([0, 0, 0, 0])\n",
    "y = torch.Tensor([[-1, 0], [1, 0]])\n",
    "batch_y = torch.tensor([0, 0])\n",
    "assign_index = knn(x, y, 2, batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33f755-70da-42f0-8475-f6058a61545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610de660-3b78-485e-994b-f3ecea3b8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from potential_field import infer_p\n",
    "collideds = []\n",
    "dones = []\n",
    "lengths = []\n",
    "for v_idx, data in tqdm(enumerate(valid_dataset)):\n",
    "    env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "    collided, done, gifs = infer_p(env)\n",
    "    save_gif(gifs, 'gifs/dubins_no_obstacle/128_'+str(v_idx)+'_'+str(np.any(collided))+'_'+str(done)+'.gif')\n",
    "    collideds.append(collided)\n",
    "    dones.append(done)\n",
    "    lengths.append(len(gifs))\n",
    "    \n",
    "print(np.mean(collideds), np.mean(dones), np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c18d09-7145-4be3-8362-b168164d42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = valid_dataset[18]\n",
    "env = Env(num_agents=NUM_AGENTS, mode='barrier', PROB=(0,OBSTACLE_DENSITY), SIZE=(MAP_SIZE,MAP_SIZE))\n",
    "env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "collided, done, gifs = infer(env, bnn, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091e1a8-3350-45b3-8593-e677a6ff1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from potential_field import infer_p\n",
    "collideds = []\n",
    "dones = []\n",
    "lengths = []\n",
    "for v_idx, data in tqdm(enumerate(valid_dataset)):\n",
    "    env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "    collided, done, gifs = infer_p(env, n_candidates=200, ignore_agent=False)\n",
    "    save_gif(gifs, 'gifs/potential/dubins/128_'+str(v_idx)+'_'+str(np.any(collided))+'_'+str(done)+'.gif')\n",
    "    collideds.append(collided)\n",
    "    dones.append(done)\n",
    "    lengths.append(len(gifs))\n",
    "    \n",
    "print(np.mean(collideds), np.mean(dones), np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03d856-189e-4c03-be91-4085e567c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from potential_field import infer_p\n",
    "data = valid_dataset[2]\n",
    "env = Env(num_agents=1, mode='barrier', PROB=(0,OBSTACLE_DENSITY), SIZE=(MAP_SIZE,MAP_SIZE))\n",
    "env.world.obstacles, env.world.agent_goals, env.world.agents = deepcopy(data)\n",
    "collided, done, gifs = infer_p(env, verbose=True)\n",
    "save_gif(gifs, 'why.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a1b7a-9d56-4450-bc52-ed22ba2f52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
